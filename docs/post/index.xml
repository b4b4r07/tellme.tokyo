<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on tellme.tokyo</title>
    <link>https://tellme.tokyo/post/</link>
    <description>Recent content in Posts on tellme.tokyo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>Copyright &amp;copy; 2017 BABAROT All Right Reserved.</copyright>
    <lastBuildDate>Fri, 05 Jan 2018 19:52:12 +0900</lastBuildDate>
    
	<atom:link href="https://tellme.tokyo/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2017年振り返り</title>
      <link>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</link>
      <pubDate>Fri, 05 Jan 2018 19:52:12 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</guid>
      <description>もう年も変わってしまったけれど、去年どのような1年を過ごしたのかを振り返る。
1〜7月、SRE になったという記事でもある通り、環境や心境の変化もあってクォータの変わり目でもある7月のタイミングでチームを異動した。 それまでは JP チームでガイドだったり大型便向けの電話対応用の API を作ったり、配送周りで上がってくる問い合わせの技術対応をしていた。
少し戻って6月は、US アプリの刷新チームにてバックエンド API のサーバサイドエンジニアをやっていた。 入社からずっと JP のことをやっていたので、US に関わったのはとても新鮮だった。
7月、SRE になったのだけれど、まずなにをやるべきか、ということになった。 ちょうど全社的に Microservices 化に舵を切り出したころだったので、 「Microservices への技術転向を支える基盤づくりをする」SRE メンバーになることを当面の目標として、 そのために必要な技術の学習やキャッチアップを兼ねて、 社内ドキュメントツールとしてモノリシックに動いていた Crowi という Wiki サービスをコンテナ化して Kubernetes で構築してみることになった。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog  コンテナや Kubernetes、Spinnaker といった技術やツールを勉強しつつ、ミドルウェア自体のキャッチアップもこのときにやった。 仕事でありながら勉強できるという環境にあったので、とても貴重な体験だったかなと思う。 また、(今回は) Crowi という、
 Web アプリケーションを違うアーキテクチャに載せ替えるとしたときに考えるべきこと
 にフォーカスしながらミドルウェアの勉強ができたのもいい体験だった1。 各種ミドルウェア、ソフトウェアはそれぞれのマニュアルや技術書を読むことで得られるが、 システムに落とし込んで構成を組むときに思慮するというのは今までに経験がなかったのでよかった。
また、プライベートでははてなブログで書いていたブログをコンテナ化したり Kubernetes に載せたりして GKE の勉強をしていた (GCP のクーポンが切れたのでもう GKE には載っていない)。 ちなみにちょっとずつこっちにインポートしているが、以前のブログはまだ消してはいないので残っている。
 ブログをGKEで運用し、Spinnakerでデプロイする | tellme.</description>
    </item>
    
    <item>
      <title>2017年に購読したサービス</title>
      <link>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</link>
      <pubDate>Thu, 04 Jan 2018 20:32:44 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</guid>
      <description>これらに便乗して。
  とりあえず昨年通して購読していて思い出せるものだけ列挙した。
購読したもの Amazon Prime 3,900円/年
Amazon で買い物するから。
Netflix 950円/月
映画、頻繁にみるので。
とにかく Breaking Bad はおすすめ。4周した。
http://www.breakingbad.jp/
アルバカーキに行ってロスポジョスエルマノスのチキンを食べたい。
Dropbox 12,000円/年
学生のときにヘビーに使っていたんだけど、いまはもうほとんどアクセスしていない。 オンラインストレージ自体に依存する生活をしていないので切っても良いのだけれど、昔のファイルなどを整理して移すのが面倒でそのままになっている。
GitHub 7ドル/月
ソフトウェアエンジニアなので。
https://github.com/b4b4r07
Education Plan が切れてしまい、使っていた Private Repo が Disabled になったので支払いとしては去年から。
iCloud 130円/月
50GB のプラン。iPhone のバックアップとして。今はまだ半分くらい。
写真などなどいちいち Mac にバックアップ、とか考えなくて良くなったから便利。 iPhone を新調したら「iCloud から復元」するだけで、さっきまで触ってた端末と同じ状態になる。
minikura 250円x複数個/月
購読サービスかと言われると違う気もするけれど、月額課金している便利なサービス。
使わないのに捨てられないもの (手紙、思い出の品) とかを預けている。 あとはシーズンではない洋服とか。
Apple Music 980円/月
Google Play Music、LINE MUSIC、Spotify、AWA、色々試したけどこれになった。 所持している Apple 製品が多いことが決め手だと思う。
HomePod が来たらもっと便利になると思っている。
Dartslive 315円/月
最近出たベータ版の黒いほうのアプリが超絶便利。 そのうち Phoenix も課金するかも。</description>
    </item>
    
    <item>
      <title>決済をキャッシュレス化している</title>
      <link>https://tellme.tokyo/post/2017/12/05/cashless/</link>
      <pubDate>Tue, 05 Dec 2017 08:57:17 -0600</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/05/cashless/</guid>
      <description>現状 キャッシュレスに切り替えて1年以上になる。 上京とともに現金を使うスタイルをやめた。 地方だと完全キャッシュレス化は現実的ではないが、首都圏、少なくとも都内23区においては現金を使うことなく生活できている。
よく使う決済手段は3つ。
 LINE Pay (JCB) ANA VISA Suica (VISA) モバイル Suica  他にもいくつかカードを持っているが、常用しているのは LINE Pay と ANA VISA Suica の2つで、電子マネーは Suica に絞っている。 ANA VISA Suica カードはややこしい名前だが Suica 機能 (オートチャージ設定可能) が付いた View カードで、ブランドが VISA になっている。
決済手段 LINE Pay JCB で1枚選出するとなると LINE Pay 一択かなと思う。 最高クラスの還元率 (2%) にも関わらず年会費などは不要で、コンビニなどですぐに買うことができる。 ほぼクレジットカードのように使うことができる1が、実態としてはプリペイドカード。 口座を指定しておくことで、LINE のアプリから24/7で入出金することができる。 最近はセブン銀行にも対応した2ことで、万が一キャッシュが必要になった場合、口座から LINE Pay に移して現金化するといったことも可能になった。
後述するがモバイル Suica と組み合わせると、「JCB は使えないが Suica は使える」というケースにおいてもポイントを取得することができる。
ANA VISA Suica 国内では JCB は VISA/MasterCard に遜色なく使える3が、海外だとあまり使えるところがない。 分散させるために違うブランドで、なおかつ待遇・特典のいいものを選んだ。</description>
    </item>
    
    <item>
      <title>Kubernetes 開発環境構築のいろは</title>
      <link>https://tellme.tokyo/post/2017/12/01/kubeabc/</link>
      <pubDate>Fri, 01 Dec 2017 00:54:11 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/01/kubeabc/</guid>
      <description>はじめに Kubernetes2 Advent Calendar 2017 - Qiita 1 日目です。
Kubernetes 上で動かすアプリを作ることが多くなってきていると思いますが、従来のオペレーションとは違う方法で開発やデプロイなどを行う必要があります。 Kubernetes の実行環境として GKE を例に取ると、GCP プロジェクトやその中で作った GKE クラスタ、Kubernetes ネームスペースなど、見る必要のある領域が増えるとともに今までのやり方も変わるはずです。 本記事ではその際のユースケースと、それをいい感じにしてくれるツールを紹介します。
今いるクラスタは何か 本番環境と開発環境 (Prod / Dev) でクラスタを分けることは多いと思います。 その他にもクラスタを持っていることもあるでしょう。
Continuous Delivery のプラットフォームとして Spinnaker が注目されつつあるので、Kubernetes クラスタへのデプロイはこれに置き換わる可能性1はありますが、Spinnaker がサポートしていない Kubernetes リソース (例えば、PodDisruptionBudget など) については、まだ手動で kubectl apply せざるを得ません。 また、基本的なリソースに対する apply 相当のことが Spinnaker によってできるようになったとはいえ、まだまだ手動で apply を実行したい場面もあります。 そこで気をつけたいのは、今いるクラスタとネームスペースの確認です。
Spinnaker は「デプロイ先のクラスタ」と「どのイメージを撒くか (manifest file)」をセットにして内部に持っているので「意図しないクラスタに対して意図しない manifest file をデプロイしてしまう」といった誤操作は防げるのですが、これが kubectl apply による手動だと今いるクラスタと -f に渡すファイル次第で、互い違いにデプロイしてしまうなどの事故も起こしかねません2。 毎回指差し確認するのも面倒ですし、そもそも確認を徹底するというのは有効打ではないので、常に見えるところに表示しておくのがおすすめです。
 手前味噌ですが、現在の Kubernetes クラスタと GCP プロジェクトを表示できるコマンドを書きました。</description>
    </item>
    
    <item>
      <title>SREになった</title>
      <link>https://tellme.tokyo/post/2017/11/02/sre/</link>
      <pubDate>Thu, 02 Nov 2017 01:33:34 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/11/02/sre/</guid>
      <description>最近、といっても今年の7月からですが SRE チームにジョインしました。
そもそも SRE とは Site Reliability Enginnering の略です。 Google が提唱しました。 国内ではメルカリがいち早くに改名したことでも知られています。
インフラチーム改め Site Reliability Engineering (SRE) チームになりました - Mercari Engineering Blog
ところで、今からおよそ1年前に入社エントリを書きました。
新卒でメルカリに入社した話 | tellme.tokyo
この頃ちょうど SRE 研修という名目のもと1ヶ月半ほど SRE チームにて業務の一端を担当しました。 研修という名を冠していますが、最前線にいる SRE から普通にタスクをもらって仕事したりレビューしてもらえるという、とても貴重な経験でした。 このときにインフラレイヤでのアーキテクチャ/ネットワークの設計や、実際に SRE が担っている業務領域に興味を持ち、このキャリアパスで飯を食っていきたいと思ったわけです。 無事に研修も終わり元のチームに戻ったわけですが、それ以降以前にもまして、SRE チームの動向ややりとりを羨望してました。
メルカリではクォータの変わり目や定期的な面談などで他分野への興味など広く技術のことについて話す機会があります。 そういった機会を利用しつつたびたびそれとなく話をしていた程度で、メルカリ SRE は技術力の高いチームであることもあり恐れ多くあまり声を大にしていなかったのですが、そうするうちに年も変わりたまたまあるきっかけを得ました。 それは &amp;ldquo;deeeet さんという人&amp;rdquo;が入社するっぽいぞという情報でした。 以前から尊敬するエンジニアのひとりだったのでひどく興奮したのを覚えています。
ときどき社内で話したり Go のイベントの手伝いや打ち上げなどで話す機会も多くなり、そのたびに「いつ SRE 来るんだ？」をいうジョブをもらい嬉しくも再度自分の思いを正しく伝えようと考えるきっかけになりました。 それからは上長や先輩たちに 1on1 をお願いし、今後自分がどうしていきたいのかなどを相談し、異動へのバックアップをしていただきました1。
晴れて今年の7月から SRE チームにジョインしたわけですが、チーム異動こそがゴールではないので、引き続きやるべきことをやっていく次第です。 直近では以下のようなことに手を出しつつ、Kubernetes を最大限に活用した Microservices 領域での基盤づくりなどを担当しています。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog Cloud Identity-Aware Proxy を使って GCP backend を保護する | tellme.</description>
    </item>
    
    <item>
      <title>Cloud Identity-Aware Proxy を使って GCP backend を保護する</title>
      <link>https://tellme.tokyo/post/2017/10/30/cloud-iap/</link>
      <pubDate>Mon, 30 Oct 2017 15:02:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/10/30/cloud-iap/</guid>
      <description>Cloud IAP とは  Cloud ID-Aware Proxy（Cloud IAP）は、Google Cloud Platform で動作するクラウド アプリケーションへのアクセスを制御します。 Cloud IAP はユーザー ID を確認し、そのユーザーがアプリケーションへのアクセスを許可されるかどうかを判断します。 - https://cloud.google.com/iap/
 つまり Cloud Identity-Aware Proxy (Cloud IAP、または IAP) を使うことで、任意の GCP リソース 1 に存在するロードバランサに対して、許可された Google アカウントやサービスアカウントによるアクセスのみに絞ることができます。 また、このアクセスリスト (ACL) の追加や削除などは GCP のウェブコンソールから簡単に制御することができます。
設定方法 GLB を作成する IAP を使う場合、GCP 上にロードバランサ (LB) を用意する必要があります。 これは IAP が LB に対して設定されるからです。
本記事では GKE、GCE での設定方法について説明します。 現時点で GAE にも対応していますが今回は検証しません。
1. GKE GKE で外部に公開したサービス (の Ingress) に対して ACL を設定したい、などでしょうか。 Ingress リソースを作成すると、自動で GLBC (GCE Load-Balancer Controller) が割り当てられます。 これは、GCP のウェブコンソールからも確認できます (メニュータブから Network services &amp;gt; Load balancing)。</description>
    </item>
    
    <item>
      <title>Software Design 2017年7月号に寄稿しました</title>
      <link>https://tellme.tokyo/post/2017/08/05/sd1707/</link>
      <pubDate>Sat, 05 Aug 2017 19:03:28 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/08/05/sd1707/</guid>
      <description>およそ1ヶ月ほど前に、Software Design 2017年7月号に寄稿しました。
すっかり告知や宣伝を忘れていたのですが、バックナンバーとしてまだ購入できるようですので、気になった方はお手にとっていただけると幸いです。
担当させていただいた章は、
 第2章：理論編2 シェルスクリプト初心者から中級者への次の一歩
 になります。
学生時代はよくシェルスクリプトを書いており、そのアウトプットのほとんどを Qiita やブログに載せていたため、今回このような形1で紙本になるのはとても嬉しかったです。
また機会があれば書かせていただきたいなと思います2。
  その記事をきっかけにオファーをいただきました [return] 需要があるかはわかりませんが、けじめをつけるためにも zplug の解説はどこかでしたいな、とは思っています (しかし掲載先は 1 人アドベントカレンダーのほうがいいかも知れませんね) [return]   </description>
    </item>
    
    <item>
      <title>ブログをGKEで運用し、Spinnakerでデプロイする</title>
      <link>https://tellme.tokyo/post/2017/07/30/blog-on-gke-deployed-by-spinnaker/</link>
      <pubDate>Sun, 30 Jul 2017 12:37:33 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/07/30/blog-on-gke-deployed-by-spinnaker/</guid>
      <description>このブログをはてなブログから Google Container Engine (GKE) に移行しました。
今回、移行先に GKE を選択した理由は GKE を使ってみたかったからです。ある Web サービスを GKE に移行することになったのですが、今まで Kubernetes を含め触ったことがなかったので、自分の持つサービスで練習がてらと思いブログを題材にしました。
目次
 移行のためにやったこと  ブログ用の Docker コンテナを作成 kubernetes cluster を構築 コンテナの入った Pod を動かす HTTPS 化する  記事の配信まで  Circle CI による継続的インテグレーション Spinnaker による継続的デリバリ  所感など  移行のためにやったこと 今回の移行に際し、移行周りのスクリプトや kubernetes のマニフェストファイル、及び記事自体を管理するために GitHub にリポジトリを作りました。
 1. ブログ用の Docker コンテナを作成 まずはブログを配信するためのサーバを載せたコンテナを作成します。静的サイトジェネレーターには Hugo を利用しました。
FROM golang:1.8-alpine AS hugo RUN apk add --update --no-cache git &amp;amp;&amp;amp; \ go get -v github.</description>
    </item>
    
    <item>
      <title>最強のヒストリ補完を作りました</title>
      <link>https://tellme.tokyo/post/2017/06/13/history/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/06/13/history/</guid>
      <description>最強のヒストリ補完を求めて シェルヒストリに不満を持っていたので自作しました。 今の自分にとっては必要な機能を盛り込んでいて便利に使えていますが、誰かにとっては、もしくは数カ月後の自分にとってはぜんぜん最強じゃないかもしれないです。
以前このようなエントリを書きました。
[http://www.tellme.tokyo/entry/2017/02/14/214231:embed:cite]
このころから (いやもっと前から) シェルのヒストリ補完に不満を持っていました。
 単純にデフォルトの C-r だと目的のものを探しづらい  例えばコマンド名の一部だけだとノイズが多すぎる けどディレクトリは覚えているからそれでもフィルタしたい、とか   他にも色々あって (その理由について先のエントリを見てもらうとして) zsh-history というツールを書きました。
https://github.com/b4b4r07/zsh-history
このときは最強のヒストリ補完ができたと、嬉々として先程のエントリを書いたのです。
しかし、まあ数ヶ月使っていると不便な点が見えてきて、
 複数ホスト間でもヒストリ共有したい ディレクトリだけではなくブランチごとに履歴を持ちたい カジュアルに履歴を消したい などなどの変更を加えるときに SQLite3 だとめんどい パフォーマンスは落ちるかもしれないけどテキストで持ってたほうが何かと便利かも  みたいなことが相まって作り直そうと思ったわけです。
新しく作った 特徴など 前回のネーミングセンスなさから変わらず、単に history となっています (そもそも前回のときのも zsh- prefix をつける必要性なかったので)。
 何ができるかというと、
 peco/fzf などでフィルタできる ブランチとかディレクトリに限定してフィルタできる (任意) 自動でバックアップしてくれる gist 経由で同期できる  GITHUB_TOKEN さえ渡せばよしなにやってくれるので、ユーザは他の PC でトークンを設定して history sync するだけ  同期のタイミングとか時間間隔とか差分量 (100 行以上で同期、など) の設定ができる 履歴を直接編集できる zsh intergrate は書いてるので source misc/zsh/init.</description>
    </item>
    
    <item>
      <title>Crowi 用の API Client 書いて公式に取り込まれた</title>
      <link>https://tellme.tokyo/post/2017/04/04/go-crowi/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/04/04/go-crowi/</guid>
      <description>Crowi というオープンソースソフトウェアの wiki があります。
 Markdown で書ける wiki で、
 Markdown をオートプレビュー URL (パス構造) でページを作成/表現できる リビジョンヒストリ (差分を管理してくれる) いいね、ブックマーク、ポータル機能、&amp;hellip;  などの特徴があって、とても便利なサービスです。
簡単に Heroku to deploy できるので気になる方は試してみてください。開発者向けにはオールインワンの Docker が有志によってメンテされているので、そちらを試してみても良いかもしれません。
go-crowi Crowi 用の API Client を Go で書きました。
https://github.com/crowi/go-crowi
Go で API Client は初めて書いたのですが、@deeeet さんの記事が参考になりました。
GolangでAPI Clientを実装する | SOTA
もともと、Qiita:Team からの移行ツールを Go で書いていたのですが、Crowi API と通信する部分は外部パッケージとして切り出したほうが汎用的に良いなと、go-crowi を作りました。
https://github.com/b4b4r07/qiita2crowi
このツールは Qiita:Team からのエクスポート用の JSON を食わすと、指定した Crowi に記事を作成してくれるものです。Qiita から画像を取ってきてアッタチメントしたり、コメントなども移行してくれます。
Transfer to Crowi そして今日、Crowi のメインメンテナの @sotarok さんから公式においても良いかも、というお話をいただき transfer しました。</description>
    </item>
    
    <item>
      <title>golang で zsh history を SQL 的に活用する</title>
      <link>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</guid>
      <description>僕は開発中、zsh のヒストリー補完の機能をよく使います。具体的には次のような場面が多いです。
 多用するコマンド  結局開発中に使うのはエディタ (vim) と git サブコマンドに集中する ちょちょいと ^N (↑) で履歴をさかのぼる  alias がイケてない場面  「エディタで .zshrc 開いて追加してリロード」が面倒で後回ししがち そして登録せずに終わる の繰り返し&amp;hellip; うろ覚え程度のコマンドの alias 名はもはや思い出せない 結局エディタ開いて見直したり、^R で遡ることに挑戦する  長いコマンド列になるとき  引数が多いとき、多段のパイプで繋いだとき 例えば、複数のパラメータを与えたときの curl コマンド   Ctrl-r (history-incremental-search-backward) よるヒストリーサーチが便利なのはよく知られたことですが、それに加えて peco のようなコマンドラインセレクタと zsh history を組み合わせて、過去に自分が入力したコマンドをその一部の記憶から引き出せるようにしたりして、便利になるようにカスタマイズしていました。
しかし、それでも以下のような不満がありました。
 ディレクトリごとに履歴を持ってほしい  ある特定のディレクトリでのみ使うコマンドなど git checkout ブランチ とか (git 系全般にいえる) プロジェクトのリポジトリとか tmux などで zsh を複数立ち上げているときなどにヒストリーを混同したくない  コマンド履歴にタグを付けたい  コメント (interactive_comments オプション) をつけて保持しておきたい あとあと検索が楽になる  すべての履歴を保持したい  何件まで保存、などは考えたくない 数年前の履歴も引き出せるようにしておきたい ただし数十万〜件になろうともパフォーマンスは落としたくない 標準のヒストリーは数十 MB にもなると、もたつく等の報告例あり  特定の月に使用したコマンド履歴を出したい  一定期間だけ違うプロジェクトにアサインされていたとか  substring search したい  これもディレクトリごとにできるとよし  history が壊れないような仕組みがほしい  突然壊れたとの報告例あり (自分は経験したことないけど) Twitter で検索すると嘆いている人が多い   zsh のオプション (setopt) や Third-party 系のプラグインなどを併用すれば一部の課題は解決できるのですが、同時に満たしてくれるものはなく自作しました。</description>
    </item>
    
    <item>
      <title>かゆいところに手が届く系の Git Tips 話</title>
      <link>https://tellme.tokyo/post/2016/12/20/git-tips/</link>
      <pubDate>Tue, 20 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/20/git-tips/</guid>
      <description>この記事は Git Advent Calendar 2016 の 20 日目です。git コマンドを日常的に実行するわけですが、外部スクリプトなどで個人的に日々改善しているお話についてまとめてみました。
ブランチ切り替えを手早くする git オペレーションで add,commit 並に多用すると思うのがブランチ切り替えで、特に remote にある branch の切り替えなどをショートカットしたくスクリプトを書きました。
$ git br  で fzf/peco などのフィルタで切り替えてくれます。ブランチ切り替え系はよくある tips なのですが、何が便利かというと、remotes/origin/HOGE などのリモートにしかないブランチは git checkout -b HOGE remote/origin/HOGE してくれるようになっているので気にせずに checkout できます。
詳しくは直接スクリプトを読んでみて下さい。簡単なシェルスクリプトです。
https://github.com/b4b4r07/git-br
ローカルのファイルを GitHub で読む hub browse です。認証しなくて良いので便利です。ブランチを指定するとそのブランチで開いてくれますし、省略すると現在いるブランチで開いてくれます。
$ git open  フォークして引数にファイル名を渡したら GitHub で開いてくれるようにしたのですが、まだマージされていません。が、僕のフォーク版だと、そのブランチのファイルを開いてくれます。
https://github.com/b4b4r07/git-open
大量のコンフリクトファイルを捌く 多人数で開発するとなると、ブランチ運用がマストなわけですがコンフリクトもまぁ発生するわけです。特に、DB の DNS 設定ファイルなどは同時に多人数が編集することも多く、衝突しやすいファイル群のように思います。解消するファイルが多数ある場合、修正して add するまでどれが完了したかいまいち分かりづらかったので、エディタで編集後にすぐ自動で任意の git コマンドを実行してくれるスクリプトを書きました。
https://github.com/b4b4r07/git-conflict
SSH に切り替える pull や push には HTTPS と SSH が選べると思いますが、SSH がいいときもあります。切り替えが面倒なのでこれを簡単にしました。git remote set-url し直すだけのスクリプトですが、長々とタイプしなくて良いので意外と便利です。</description>
    </item>
    
    <item>
      <title>実用 Slack bot ヤマト編</title>
      <link>https://tellme.tokyo/post/2016/12/12/yamato-bot/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/12/yamato-bot/</guid>
      <description>この記事は Slack Advent Calendar 2016 - Qiita の 12 日目です。
はじめに 最近のエンジニアは Slack に常駐していることが多くなってきたと思います。ゆえに bot が便利であることはご存知かと思います。受け取った文字列を echo する bot や、ランダムに画像を返す bot もその練習としてはいいですが、次のステップに bot を書くとしたら実用的なものを書きたいですよね1。
配送状況を通知する そこで書いたのが、荷物 (ヤマト) の配送状況が変わったら通知してくれる bot です。
 次のような機能を持ちます。
 bot yamato 追跡番号 とすると bot が追跡番号を監視するようになります 現在の配送ステータスを記憶するので変わったら通知してくれます  とりあえず、注文した荷物の追跡番号が発番されたら bot に向かって教えてやればよいです。すると bot は定期的に配送状況をチェックしてくれるようになります。
配送ステータスが変わると以下のように教えてくれるので、ユーザは荷物に対して受け身でいることができます。便利！
 まだ、積み残しも多いですがこれだけでも十分に便利でした。個人 Slack にでも通知してやりましょう。
謝辞 この bot では nanoblog さんによるヤマト運輸の配送状況を確認する API を使用しています。
 [WebAPI]ヤマト運輸の配送状況を確認するAPIを作ってみた [YamaTrack]ヤマト運輸の荷物問合せサイトを作成しました  終わりに この bot は Node.js で書いてます。Botkit のおかげでサクッと書けるのは良いのですが、デーモン化するにあたり forever を利用していると色々モヤることが多く、現在は Go 言語 (Supervisord) で書き直しています (本当は間に合わせるはずだった)。</description>
    </item>
    
    <item>
      <title>最近の Vim のプラグイン管理について考える</title>
      <link>https://tellme.tokyo/post/2016/12/05/2016-vim-plugin/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/05/2016-vim-plugin/</guid>
      <description>この記事は Vim Advent Calendar 2016 の 5 日目の記事です。
以前、neobundle.vim と vim-plug の比較記事を書きました。 それから数ヶ月後、dein.vim が登場し、再び比較記事を書こうと思っていたのですが、気づけばあれから 1 年が経っていました。 この記事は半年前 (&amp;lsquo;16年8月頃) に大枠だけ書き Qiita の限定共有に投稿していたのものを Advent Calendar 向けに書き下ろしたものです。
Vim プラグインの歴史 GitHub 以前 (〜2008年) 昔の話です。 Vim script で拡張の機能を書いたらそのスクリプトを vim.org にアップして開発者同士で共有したり、ユーザがダウンロードして使っていたようです。 おそらくコレが所謂「プラグイン管理」の始まりなのですが、このときはまだ手動で行われていたようです (残念ながら、このときはまだ Vim に出会っていなかったためその肌感は分かりません&amp;hellip;)。
例えば、こんな機能も Vim script で書いた拡張です (autogroup などは考慮してません)。
autocmd BufWritePre * %s/\s\+$//e  Vim 7 から Vimball という機能が Vim 本体に同梱されて、それからはこれを利用するユーザもいたようです。 vim.org からアーカイブされたスクリプトを持ってきて、:so % したり、気に入ったら runtimepath 以下に置いて自動読み込みしたり。 その頃の plugins ディレクトリは混沌としていたようです。 ペライチのスクリプトが無造作に転がっており、同名ファイルに気をつけたりアップデートの情報は自分でキャッチしなければなりませんでした。
GitHub 以降 (2008年〜) GitHub は 2008 年頃発のサービスですが、翌年には最大の Git のホスティングサービスになっていたようです。 本格的に流行りだしたのは 2011 年ころの印象を受けますが、このソーシャルコーディング時代の新風は Vim プラグイン界にも訪れ、席巻したようです。</description>
    </item>
    
    <item>
      <title>builderscon tokyo 2016 に参加してきました</title>
      <link>https://tellme.tokyo/post/2016/12/04/builderscon2016/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/04/builderscon2016/</guid>
      <description>引用
 buildersconは「知らなかった、を聞く」をテーマとした技術を愛する全てのギーク達のお祭りです
 tl;dr  builderscon tokyo 2016 に参加して、  裸で登壇された生 mattn さんを見て、 みんなを楽しませる技術力に凄いなぁと改めて思わされ、 自分も何か作りたい衝動に駆られた   Opening 牧さんによるオープニングでした。いきなり第2回開催予定の告知からスタートし会場が少しざわめきました。まだ、第1回の builderscon すら終わってないのに、このタイミングでの告知は、サプライズ感だけでなく絶対成功させるぞという気概を感じさせるとともに、コンセプトにもあるお祭りっぽさがあってとてもワクワクさせられました。
OSS は Windows で動いてこそ楽しい @mattn さんによる発表でした。僕ははじめてお目にかかりました。(見た目は) 普通以上に普通なのに、異常なエンジニアリング力です。改めて尊敬し直しました。Vimmer であり、時折 Go も書く自分としては一番楽しみにしていた発表でした。案の定、Go で Windows OSS 開発の未来が明るくなる話や、Vim の新作ネタプラグイン (畏敬の念を込めてネタプラグインと呼ぶ) などが発表されました。個人的に、Vim 界隈に長年貢献されてきた mattn さんと kaoriya さんのツーショットや、mattn さんの Vim 環境 (青っぽいリッチステータスラインに Solarized Dark なテーマ) を生で見られたことに感激しました。
php.ini について知る @uzulla さんによる発表でした。PHP を書くことが多くなった自分としては聞いときたいなと思い、聞いていたのですがやはり思った以上に知らないことが多く (PHP が ini を解釈するときは想像以上にゆるふわ) とても勉強になりました。&amp;quot;true&amp;quot; って true じゃないとか、ini ファイルのパス解決順序で最後に読まれた ini が適用されるので気づかないでハマってたり、なんかつらそうだという印象でした。良くも悪くもそこが PHP の特徴なところもあるようで、うまく折り合いながら向き合っていく気合が必要とのことでした。発表終了間際に発言されていた「php.</description>
    </item>
    
    <item>
      <title>運営として VimConf 2016 に参加してきた</title>
      <link>https://tellme.tokyo/post/2016/11/06/vimconf2016/</link>
      <pubDate>Sun, 06 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/11/06/vimconf2016/</guid>
      <description>株式会社ミクシィさんにて行われた VimConf 2016 の参加レポートです。自分は一般参加者としてではなく、一部運営に携わったのでその点について主に書ければなと思います。
tl;dr   VimConf 2016 のまとめ役として参加しました スライドの感想や資料については他の方のレポートを見てください 「ババロットさん、アイコン変えた方がいいよ」  まとめ役として参画した背景 ある日突然、社内 Slack の個人チャンネル (分報的なアレ) にてこんなポストが投げられました (リンクだけ)。
  二つ返事で参加レスをしたわけですが、これはノリで運営やってみました、とかでは全くないです。日々、Vim を使い vim-jp やその界隈の人たちのプラグインなどを使ったりし感謝していくうちに、いつかコミュニティに携わりたい・還元したいという気持ちが芽生えていたためです。たまたまこの煽りポストがいい後押しとなり、運営への参画を踏み出すきっかけになったのでした。
ひとり KPT まとめ役という肩書きで参加したわけですが、色々振り返ってみるとやり残したことや課題感、続けたいことなどが見えたのでまとめてみます。
 KEEP  VimConf 2017 への参画  せっかく自分の中に溜まったノウハウをここで途絶えさせるのは勿体無いので、次回も何らかの形で携わりたい。貢献し続けることも大切  参加率の良さ  9 割近くの参加率、総勢約 120 名での VimConf は初のこと。募集開始を遅らせたりなどの工夫があった。果たしてこれが功を奏したかは来年も試してテストしてみないとだけど  ケータリングの量  多すぎず少なすぎずで懇親会終わる頃にちょうど綺麗になくなった感。廃棄もほとんどなかったんじゃないかな。ここは自分ががっつり噛んでいたところなので見事な新卒力を発揮できた  交流が活発に見えた  誰とも話せない、という人はいなかった気がします。それとドリンク島がドリンクを求めた立ち寄った人との交流の場になっていたのは良かった   PROBLEM  コミットが足りなかった  TRY: 忙し月と準備が被った。次回も参加することで乗り越えていきたいところ  意外とバタバタ@懇親会準備1  TRY: 各種業者に当日リマインダを掛けられたのはよかった。ただ、一部到着連絡をもらえず開場まで運ばれたのには焦った (受付に人がいて気づいてくれた. いなかったらと思う図ちょっとゾッとする)。  意外とバタバタ@懇親会準備2  TRY: 皿や紙コップ、醤油や小皿のデプロイに手間取った。これは前々からその準備が必要だなって思った。発表中にごそごそするわけにもいかないだろうし。    印象に残ったこと # TODO: ババロットさんに中年エンジニアと誤認していたことを謝る。https://t.</description>
    </item>
    
    <item>
      <title>新卒でメルカリに入社した話</title>
      <link>https://tellme.tokyo/post/2016/10/01/mercari/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/10/01/mercari/</guid>
      <description>タイトルの通りです。 16年卒の学部卒新卒として株式会社メルカリに入社しました。 入社したのは今年の 4&amp;frasl;1 なので半年前のことです。 なぜ今頃になって入社エントリを書くのかというと、先日新しいメディア立ち上げにともなう記事一発目としてインタビューを受けたのですが、その記事が 10&amp;frasl;3 に公開されるとのことで、他者に明らかにされるならばその前に自分から入社エントリを書こうと思ったことと、タイミング的にも今日という日はちょうどいいなと思ったからです。
tl;dr  新卒でメルカリに入社しました メルカリでは新卒採用もしているので興味があれば言ってください  メルカリという会社  https://www.mercari.com
メルカリが新卒採用を始めたのは今年からなので、僕は第一期新卒ということになります。 最近ではとても有名なアプリ・会社になってきて、国内での勢いはもちろんのことアメリカでも急成長してきており、今後の動向にワクワクしつつ日々携わっております。
16 新卒は 6 人いて、今は 17&amp;frasl;18 卒の新卒採用に向けて動いています。 採用会食など、まずは話から聞いてみたいなという方がいましたら、僕経由で繋ぐことができるかもしれませんので興味があれば Twitter DM でもいいですし、コンタクトいただければなと思います。 新卒・中途採用どちらでも OK ですし、時期に関しても関係ないと思います（次の新卒がこの時期に連絡しても問題ないのかという意味で）。
入社までの経緯 プログラミングといえるようなことは大学に入ってからはじめました。 C 言語の開発環境 (bash on Linux) に慣れなかったことから、色々改善しようと .bashrc のカスタマイズにのめり込み、シェルスクリプトを覚えるようになりました。 同時に Emacs に慣れずにエディタには Vim を使うようになり、同じく .vimrc のカスタマイズ (Vim script) にハマりました。 夢中になって気づいたら朝ということも何度かあった気がします。
もともと、Windows を使っており、当時 AutoHotkey と超低機能 2 画面ファイラの「あふｗ」 (敬意を込めて) のカスタマイズにハマっていたことから、Linux でのカスタマイズについても夢中になることは明白でした。 これを機にと macOS (当時の表記で言う Mac OS X。 途中から OS X) に乗り換えたことで、更にそれは加速したような気がします。 しかし、シェルスクリプト力とエディタ力は上がれど、なかなか他の言語を集中して覚えることがなく、しばしば悩んでおりました。</description>
    </item>
    
    <item>
      <title>最近、httpstat なるものが流行っているらしい</title>
      <link>https://tellme.tokyo/post/2016/09/25/httpstat/</link>
      <pubDate>Sun, 25 Sep 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/09/25/httpstat/</guid>
      <description>おそらく先行実装は python で書かれたこれです。
  curl にはウェブサイトの応答時間を計測する機能が搭載されており、このツールではそれを利用して出力結果をグラフィカルに表示させています。 単なる curl のラッパーのようなツールなのですが、見た目がリッチになるのに加えて、単一ファイルで実行でき python のバージョンに影響されないような工夫がされているのが、受けているポイントのような気がします。
このツールを見たとき「Go で書いてみるの良さそう！（この手のツールで単一バイナリになるのは嬉しいですよね）」と思い、休憩時間やお昼休みなどにちまちま書いていたら、二日前に先を越されてしまいました（そりゃそうですよね。なんでもスピードが大事だと痛感）。
  また、ついこの間まで 800 Stars くらいだったのですが、ここ1週間で爆発的に伸びています（記事投稿時 1,100 Stars）。 これを機になのか、色々な実装を見るようになりました。知らないだけで他にもあるかもしれません。
 yosuke-furukawa/httpstat (JavaScript) tcnksm/go-httpstat (Go package) talhasch/php-httpstat (PHP)  Go で先を越され少し悔しい気もするので、curl のラッパーだしシェルスクリプトでも書いてみようと思い、書いてみました。 なんのメリットがあるかは分かりませんが、bash オンリーで書いているので bash のある環境であれば動くはずです。
 次に時間があるときは Vim script で書こうかな。</description>
    </item>
    
  </channel>
</rss>