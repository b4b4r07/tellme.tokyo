<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on tellme.tokyo</title>
    <link>https://tellme.tokyo/post/</link>
    <description>Recent content in Posts on tellme.tokyo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>BABAROT All Right Reserved.</copyright>
    <lastBuildDate>Mon, 19 Nov 2018 20:08:07 +0900</lastBuildDate>
    
	<atom:link href="https://tellme.tokyo/post/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>GitHub のラベルを宣言的に管理する</title>
      <link>https://tellme.tokyo/post/2018/11/19/github-label-management/</link>
      <pubDate>Mon, 19 Nov 2018 20:08:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/11/19/github-label-management/</guid>
      <description>ソフトウェアの宣言的設定について &amp;ldquo;何かを管理する&amp;rdquo;となったときに、宣言的に設定できるようになっていると非常に便利である。 この宣言的設定 (Infrastructure as Code) とは、イミュータブルなインフラ (Immutable Infrastructure) を作るための基本的な考え方で、システムの状態を設定ファイルにて宣言するという考え方である。 具体的には Kubernetes のマニフェストファイル (YAML) だったり、Terraform のコード (HCL) が挙げられる。 この考え方は、インフラ領域に限らず、何らかの状態管理にはもってこいの手法である。
GitHub のラベルは Issues/P-Rs を管理するために便利な機能である。 しかし、リポジトリの規模やラベルの数が増えてくると、ラベル自体も管理する必要が出てくる。 実際に Kubernetes 規模のリポジトリになると、ラベル管理なしにはやっていられない。 ラベルを管理するための bot やツールすら動いている。 実際に Kubernetes のコミュニティでは現在 180 個近くのラベルが定義されており、同様のラベルが導入されているリポジトリが数十個ある。
 Labels - kubernetes/community  1つのリポジトリのラベルを管理するくらいならマニュアルでも可能だが、複数リポジトリとなるとリポジトリ間の同期が大変になってくる。 特に ZenHub などの GitHub Issues を使ったマネジメントをしている場合、ラベル名が一致されていることとその付随情報 (色や説明) の同期が必須になる。 人間が手で追加や変更をしていると、必ず差異が発生する。
ここで、冒頭に挙げた宣言的設定が有効な手段になる。
github-labeler の紹介 https://github.com/b4b4r07/github-labeler
宣言的設定の手法をラベル管理に持ち込むために、GitHub ラベルの定義とそれを作るリポジトリについて「YAML に書いたとおりになる」ツールを書いた。
例えば次のような YAML を書く。
labels: - name: area/security description: Indicates an issue on security area.</description>
    </item>
    
    <item>
      <title>『僕たちはファッションの力で世界を変える』を読んだ</title>
      <link>https://tellme.tokyo/post/2018/11/08/the-inoue-brothers/</link>
      <pubDate>Thu, 08 Nov 2018 22:37:54 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/11/08/the-inoue-brothers/</guid>
      <description>  The Inoue Brothers - In The Land of The Alpaca from Present Plus on Vimeo.
 デンマークで生まれ育った日系二世兄弟、井上聡(1978年生まれ)と清史(1980年生まれ)によるファッションブランド。2004年のブランド設立以来、生産の過程で地球環境に大きな負荷をかけない、生産者に不当な労働を強いない&amp;rdquo;エシカル(倫理的な)ファッション&amp;rdquo;を信条とし、春夏は東日本大震災で被災した縫製工場で生産するTシャツ、秋冬は南米アンデス地方の貧しい先住民たちと一緒につくったニットウェアを中心に展開する。さまざまなプロジェクトを通して、世の中に責任ある生産方法に対する関心を生み出すことを目標にしている。聡はコペンハーゲンを拠点にグラフィックデザイナーとして、清史はロンドンでヘアデザイナーとしても活動。そこで得た収入のほとんどを「ザ・イノウエ・ブラザーズ」の運営に費やす。
 https://theinouebrothers.net/
とてもいい本だった。 井上兄弟は中央アンデス高地に暮らす人々とそこに生息するアルパカから採れる毛を利用した最高級ニットを手がけるブランドクリエイターである。 彼らの精神性とプロダクトに対する強い想いに感動したのでまとめておく。
ブランドが掲げるコンセプト「Style can&amp;rsquo;t be mass-produced」  “Style can&amp;rsquo;t be mass-produced&amp;hellip;（スタイルは大量生産できない）”
 5年前にファストファッションなどに代表される大量生産・大量消費社会のしわ寄せともいえる事件がバングラディシュで起きた 1。 欧米西洋日本をはじめとする先進国の人たちの、最新のファッションやトレンドの服を安くたくさん手に入れたいという気持ちに応えるために、1円でも安く受注できる工場を発展途上国に委託する。 そこでは若い女性が低賃金で過酷な労働を強いられている。 労働環境などは二の次で、生産数を増やすために違法な増築改造を続けたがゆえの事件だった。
もちろんこのビルのオーナーや現場監督が悪い、という話になるのだが、もとを辿ればその上流から来ている問題だった。 たとえハッタリだとしても「君のところより安く受注できるところがあるから切るよ」と言われてしまうと、現地の工場は大量の労働者を路頭に迷わせてしまう。 そうならないためにもとことんコストを切り詰めないといけない状況になっていた。 こういった潮流を作っているのはあくまでもファストファッションブランドであり、現地の労働者も、地球の裏にいる消費者もそのことに気づいていない。 知っているのはブランド側だけである。
イノウエブラザーズはこういった大量生産・大量消費にはやくから疑問をもち、エシカルを信条とし生産者から購入者（≠消費者) までのプロセスに関わるすべての人が幸せになれるような、ダイレクトトレードの先駆けとして活動をしているブランドだった。
最高のプロダクトを現地の人と一緒に作る  “チャリティではなくビジネス”とふたりがよく口にするのは、施しは一時的な助けになっても、自立を促すための手段にはならないと考えるからだ。
 印象に残った言葉に&amp;rdquo;チャリティではなくビジネス&amp;rdquo;というのがある。 彼らは何度もアンデスの地に足を運ぶ中で、社会的な不公平や貧困、高山地域での暮らしの厳しさなどを目の当たりにしていた。 そこで施しを与えることはできるけど、自分たちは一時的な助けではなく、あくまでは彼らはビジネスパートナーであり彼らと一緒になって最高のプロダクトを作り、値段は高くはなるかもしれないが、適切なものに適切な価格を添えて世界に発信することで、ひいては彼らの生活水準を上げることにつながると考えたいたからこその発言だった。
もともと中央アンデス高地に暮らす人々の暮らしにアルパカは馴染んでおり、人々はその毛を刈り売ることで生活していたが、刈るための道具が石器の類でうまく切れずに毛やアルパカを傷めてしまうだったり、アルパカの毛の細さで価値が変わることだったり、採れる部位で価値が変わることなどを知らないという現実があった。そこで彼らに毛刈りハサミや電動シェーバーだったりのことを伝えたり、毛の刈る部位によってパッキングして卸したりするように伝えたりなどのところから始めた。
フェアトレードによるアルパカ自体の保全や現地の人の暮らしをまもりたいという志しで、ペルーの高地にあるパコマルカアルパカ研究所とパートナーシップを築き、地元の放牧者が自らの生活様式から上手く利益を上げられるように援助している。現地の研究所と対話しながら、世界で一番高品質の「シュプリームロイヤルアルパカ」を開発するなど、現在ではアルパカ製品の世界的なエキスパートになっている。
感想として  「本当の価値を決めるのは、希少性でも価格でもない。そこにどれだけ、つくり手の熱い情熱と魂を込められるかなんだ」
 この言葉にある通り、ものづくりに対する熱すぎる情熱とアルパカ製品で世界一のプロダクトを作るということへの想いが込められていると思った。 井上兄弟は端々に&amp;rdquo;世界&amp;rdquo;だったり&amp;rdquo;正義&amp;rdquo;、&amp;rdquo;平和&amp;rdquo;だったりといった少しくさいような、独善的な表現を用いるがそれは軽々しく言っているわけではなく、本当にそうしたいと思って実行し、裏付けとなる行動とともに成果を出していて、生き様としてかっこいいと思った。そしてその生き様が作るプロダクトに反映されていて、そのストーリー性やバックグラウンドの惚れ込み、アイテムへの愛着が湧いた。
最近では、次の写真のように、長く愛用してほしいという想いから天然の防虫剤としても知られる楠にメッセージを刻印したものを付属してくれている。こういった自分たちのプロダクトへの愛情とそれを購入者へ伝えたいという気持ちを見ることができて、なんとも言えない嬉しいような感動のような気持ちが湧いた。
リファレンス  世界一のアルパカニットを作る兄弟「ザ・イノウエブラザーズ」とは？ 過酷な低賃金ビジネスはもうやめよう──『僕たちはファッションの力で世界を変える』 | BNL (Business Network Lab) | Eightが運営するメディア 最高のクオリティを求めて南米を旅する兄弟──ザ・イノウエ・ブラザーズ｜メンズファッションニュース｜GQ JAPAN   ファストファッションの裏側　ラナプラザの悲劇の意味 | エシカルファッションのセレクトショップ A Scenery Beyond&amp;hellip;のエシカルマガジン [return]   </description>
    </item>
    
    <item>
      <title>スムーズに Hugo でブログを書くツール</title>
      <link>https://tellme.tokyo/post/2018/10/16/write-blog-smoothly/</link>
      <pubDate>Tue, 16 Oct 2018 13:18:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/10/16/write-blog-smoothly/</guid>
      <description>このブログ (b4b4r07/tellme.tokyo) ではマークダウンで記事を書き、Hugo を使って静的ファイルを生成して GitHub Pages でホスティングしている。
とても便利なのだが、いくつか面倒な点がある。
 リアルタイムに記事のプレビューが見たいとなると、hugo server -D する必要があり、都度別コンソールで立ち上げるのが面倒 記事をあたらしく書き始めるとき hugo new post/&amp;lt;filename&amp;gt;.md を打つのが面倒 過去記事を編集するのが面倒 hugo を実行すると draft の記事も生成されてしまう (index には載らないが、生成されるので commit してしまう)  いろいろ面倒なので、Hugo でブログを書くだけのツール (hugo wrapper) を書いた。 hugo の上位互換というわけではなく、必要な機能の不便な部分だけを Override しているだけのツールなので合わせて使っていく。
tellme.tokyo/cmd/blog at master · b4b4r07/tellme.tokyo
Usage: blog [--version] [--help] &amp;lt;command&amp;gt; [&amp;lt;args&amp;gt;] Available commands are: edit Edit blog articles new Create new blog article  簡単な CLI ツールになっていて、ブログを編集するときに blog edit とすれば fzf が立ち上がって記事を選択できるようになっている。
$ blog edit &amp;gt; 39/39 &amp;gt; スムーズに Hugo ブログを書くツール Windows 時代の使用ソフト晒し Bind Address で少しハマった話 Hugo で PlantUML のようなシーケンス図を描画する Kubernetes 上で Credentials を扱う HashiCorp Vault の Unseal と Rekey 東京衣食住 Microservices Platform Meetupで話した 『ルポ川崎』を読んだ  fzf との連携は b4b4r07/go-finder でやっている1。</description>
    </item>
    
    <item>
      <title>Windows 時代の使用ソフト晒し</title>
      <link>https://tellme.tokyo/post/2018/09/27/windows-era/</link>
      <pubDate>Thu, 27 Sep 2018 20:06:55 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/09/27/windows-era/</guid>
      <description>〜2013 年ごろまで Windows を使っていた (Windows 7 SP2 が最後)。 そのころはいろいろなフリーソフトにお世話になった。
画像はマイベストフリーソフト「あふｗ」。
一覧 ファイル管理  あふｗ 内骨格 Paper Plane xUI DF NexusFile X-Finder Easy File Locker  ファイル比較  df  ファイル名変更  練馬 Flexible Renamer ファイル名変更君 お～瑠璃ね～ま～  ファイル圧縮  Lhaplus Noah 7-Zip caldix  ファイル検索  Everything FileSeeker3 Locate32  ファイル暗号化  アタッシェケース ED TrueCrypt  ファイル移動  FireFikeCopy FastCopy  ブラウザ  Sleipnir kiki  アプリランチャ  CLaunch Fenrir CraftLauncher Clock Launcher cltc  IME  Google IME  テキストエディタ  Vim  オフィス  PDForcel pdfi pdft xdoc2txt SumatraPDF i2pdf LibreOffice  画像  ViX JTrim BatchGOO!</description>
    </item>
    
    <item>
      <title>Bind Address で少しハマった話</title>
      <link>https://tellme.tokyo/post/2018/08/16/bind-address/</link>
      <pubDate>Thu, 16 Aug 2018 00:55:17 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/16/bind-address/</guid>
      <description>以下の要件を満たして hugo server を立ち上げたいという要求がありテンポラリで対応することになった。
 hugo server はローカルではなく、ある GCE インスタンスで実行する ローカルから繋ぎたいが、ポートフォワードは使わない  この要件を満たすためには、
 GCE インスタンスに :1313 でつなぎに行けるようにポートを開ける (ファイアウォールの設定) ポートフォワードは使えないので、グローバル IP を取る (とりあえず Ephemeral)  以下を参考に Firewall rule を設定して、GCE インスタンスにアプライした。
How to open a specific port such as 9090 in Google Compute Engine - Stack Overflow
動作確認として適当に Serve するスクリプトで :1313 を LISTEN して nmap してみた。
package main import ( &amp;quot;net/http&amp;quot; &amp;quot;io&amp;quot; ) func helloHandler(w http.ResponseWriter, r *http.Request) { io.WriteString(w, &amp;quot;Hello world!</description>
    </item>
    
    <item>
      <title>Hugo で PlantUML のようなシーケンス図を描画する</title>
      <link>https://tellme.tokyo/post/2018/08/13/hugo-mermaid/</link>
      <pubDate>Mon, 13 Aug 2018 18:58:07 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/13/hugo-mermaid/</guid>
      <description>Hugo で PlantUML を描画して埋め込めないものかと調べていると、
 Add exec shortcode #796 - gohugoio/hugo・GitHub  Hugo の Shortcodes の機能を使って、HTML の生成をフックにしてレンダリングした後に埋め込む、みたいなことをできるようにする議論自体はあったものの進んでいないようで、他の案はないかと調べると PlantUML ではなく mermaid が良いとわかった。
vjeantet/hugo-theme-docdock にあったディレクトリ構成を真似て以下のようにした。
 b4b4r07/tellme.tokyo - f8fe64c・GitHub  Shortcodes を使って以下のようなシーケンス図を書くと、
{{\&amp;lt; mermaid align=&amp;quot;left&amp;quot; \&amp;gt;}} sequenceDiagram participant Alice participant Bob Alice-&amp;gt;&amp;gt;John: Hello John, how are you? loop Healthcheck John-&amp;gt;John: Fight against hypochondria end Note right of John: Rational thoughts &amp;lt;br/&amp;gt;prevail... John--&amp;gt;Alice: Great! John-&amp;gt;Bob: How about you? Bob--&amp;gt;John: Jolly good! {{\&amp;lt; /mermaid \&amp;gt;}}  次のようにレンダリングされる。</description>
    </item>
    
    <item>
      <title>Kubernetes 上で Credentials を扱う</title>
      <link>https://tellme.tokyo/post/2018/08/07/kubernetes-configmaps-secrets/</link>
      <pubDate>Tue, 07 Aug 2018 01:01:47 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/07/kubernetes-configmaps-secrets/</guid>
      <description>アプリケーションにロジックを外側から変更したい場合やソースコード外から設定されるべき情報 (API キーや何らかのトークン、その他の Credentials など) をアプリケーション側から読み取れるようにしたい場合がある。 よくある方法として、環境変数やフラグなどがある。
しかしこれらは往々にしてアプリケーションにハードコードされがちである (ロジックが書かれたファイル外に定義されたとしてもそれはハードコードに等しい)。 そうすると設定変更のたびにデプロイを必要とするし、言わずもがなセキュリティ的には厳しい。
またこの問題は、コンテナとマイクロサービスの領域において更に顕著になる。 同じデータを2つの異なるコンテナで参照する必要がある場合や、ホストマシンが使えないのでどうやってコンテナ内に渡すべきかを考える必要が出てくる。
実際にハードコードされたアプリケーションから環境変数に移し、それらをコンテナ化し Kubernetes に載せ替えてくステップを追う。
アプリ側にハードコードされた例 var http = require(&#39;http&#39;); var server = http.createServer(function (request, response) { const language = &#39;English&#39;; const API_KEY = &#39;123-456-789&#39;; response.write(`Language: ${language}\n`); response.write(`API Key: ${API_KEY}\n`); response.end(`\n`); }); server.listen(3000);  language やAPI キーを変更する場合は、コードを編集する必要がある。 またバグやセキュリティリーク、ソースコードの履歴を汚すアプローチである。
これの代わりに環境変数を使う。
環境変数を使うパターン Step 1: 環境変数を読み込む var http = require(&#39;http&#39;); var server = http.createServer(function (request, response) { const language = process.env.LANGUAGE; const API_KEY = process.</description>
    </item>
    
    <item>
      <title>HashiCorp Vault の Unseal と Rekey</title>
      <link>https://tellme.tokyo/post/2018/08/02/vault-intro/</link>
      <pubDate>Thu, 02 Aug 2018 19:51:52 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/02/vault-intro/</guid>
      <description>環境 HashiCorp Vault 0.10.4
Seal/Unseal HashiCorp Vault (Vault) は起動しただけでは使えない。 Vault は Sealed / Unsealed という自身の状態を表すステータスの概念を持ち、これらを内部で保持する一部ステートフルなアプリケーションである。
Vault は起動時 (再起動、デプロイ後など) は Sealed 状態となっており、Secret の取得や保存など、あらゆるオペレーションができないようになっている。 これはセキュリティを高めるために Vault が用意したプロセスである。
Vault では暗号化したデータを外部ストレージに保存する (Secret Backend と呼ぶ) が、復号して取り出す際に暗号化に使用したキーを必要とする。 この暗号化キーも暗号化されたデータとともに Secret Backend に保存されるが、マスターキーという別のキーで暗号化キーを暗号化している (ちなみにこのマスターキーは Secret Backend には保存されない)。 そのため、何かデータを復号して取り出すには、暗号化キーを暗号化したマスターキーが必要になる。
 例
少しややこしいのでこれらを銀行に例えると、
 マスターキー: 銀行という建物に入るための鍵 暗号化キー: 銀行という建物の中にある保管庫の鍵 秘密: 銀行という建物の中にある保管庫の中にしまってある  (Vault では保管庫は銀行という建物の中にないので実際には少し違うが) 秘密を取り出すにはまず銀行の中に入るための鍵が必要で、その次に保管庫の鍵が必要になる。 また、保管庫の鍵は銀行内にあるが銀行に入るための鍵は銀行の外にいる (複数の) 行員が持っているため、この銀行の鍵を準備する (Unseal) 必要がある。
 上で説明したように、Vault でデータを取り出すためには、 Sealed 状態を解除する必要があり、そのためにはマスターキーが必要になる。 Vault サーバ (クラスタ) ははじめて起動するとき (Initialize) に、マスターキーを5つのシャードに分割して Vault クライアントに提示する (Unseal Keys)。 再度、マスターキーを構築するためには3つ以上のシャードを必要とする。 これにはシャミアの秘密分散法というアルゴリズムが用いられている。 ただし、Vault はこれらのシャードキーをどこにも保存しないので、Initialize をした者は別途保管する必要がある。</description>
    </item>
    
    <item>
      <title>東京衣食住</title>
      <link>https://tellme.tokyo/post/2018/08/01/tokyo-life/</link>
      <pubDate>Wed, 01 Aug 2018 03:48:04 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/08/01/tokyo-life/</guid>
      <description> 五十音順。2018年版
衣  AURALEE JieDa NEEDLES NEON SIGN Sasquatchfabrix. URU bukht crepuscule dairiku doublet kolor  食  BUZEN 丸香 八兵衛 山半 山長 (恵比寿) 源八 (北澤) 珈琲コーラル  住  三田、芝 上野、稲荷町、入谷 下北沢 中目黒 広尾 新江古田 江ノ島 (神奈川県) 豊洲、東雲 鎌倉 (神奈川県) 高円寺 麻布十番  </description>
    </item>
    
    <item>
      <title>Microservices Platform Meetupで話した</title>
      <link>https://tellme.tokyo/post/2018/07/23/microservices-platform-meetup/</link>
      <pubDate>Mon, 23 Jul 2018 14:35:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/07/23/microservices-platform-meetup/</guid>
      <description>-- Microservices における Terraform の活用とユースケースについて話した。
 Microservices とは UNIX の設計思想にもある Make each program do one thing well をもとに書き直し、1つのアプリケーションを複数のサービス (コンポーネント) に分割して、独立して稼働できるようにしたもの。
Monolithic architecture にも Pros/Cons があり、Microservices architecture にも Pros/Cons があるのだが、Monolith から Micrroservices へ移行する際の Cons の1つとしてインフラの Provisioning が挙げられる。 Monolith の場合だと、新機能の追加は同じコードベースをいじることで解決できることが多く、その場合既存のインフラを使いまわしてデプロイすることで実現できる。 しかし、Microservices の場合だと Isolation の観点からインフラを独立させる必要があり、新機能追加 (つまり、Microservices の新規作成) のたびにインフラを用意することがコストとなる。 また、アーキテクチャと同じようにチーム構成をサービス単位で自己組織化させる必要がある (Developer, QA, SRE, &amp;hellip;) のだが、各 Developer がインフラの準備をする必要がある。 インフラ構築・運用に不慣れな Developer をアシストしつつ、これらのブートストラップを自動化する Solution が必要になる。
こういった背景がありその問題点を解決するツールとして Terraform を導入し、Terraform Module を使って Automation / Infrastructure as Code しているという話をした。 この仕組みのおかげで今では Developer は One command で Microservices に必要なセットを構築することができるようになっている。</description>
    </item>
    
    <item>
      <title>『ルポ川崎』を読んだ</title>
      <link>https://tellme.tokyo/post/2018/05/29/repo_kawasaki/</link>
      <pubDate>Tue, 29 May 2018 12:18:56 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/05/29/repo_kawasaki/</guid>
      <description>本作は帯にある「ここは、地獄か？」という謳い文句のとおりに現代のディストピアと言われる神奈川県・川崎市 (とくに川崎区) を舞台に書かれたルポルタージュ (現地報告) である。
著者が川崎をテーマにルポルタージュを書くにいたったのは、2015年から立て続けに起こった川崎中一殺害事件や簡易宿泊所火災、ヘイトデモといった象徴的事件が背景にある。 こういった陰湿かつ世間を驚かせるような事件が相次いだ川崎区を、現代日本が抱える社会的問題を象徴する場所として捉えた上で、その事件のバックグラウンド (深層) に入り込むことで「今の川崎から見えてくるものは何か」という現地取材による連載から始まったものである。
川崎市 (川崎区を含む七区からなる) は長年、東京と横浜の間に位置する土地柄を生かしてベットタウンとして開発されてきた過去を持つが、市の最南であり東京湾に面する川崎区は今でこそ川崎駅周辺の観光地化などによりクリーンなイメージを持ちつつあるが、もともとはその臨海部・工業地帯という性格から、そこで働く労働者のための「飲む・打つ・買う」を中心に発展した区である。現在でも中心部から少し外れれば、ソープランドや競輪競馬といった合法的なものからや非合法な娯楽場なども数多く営業し、それらの資金が最終的に流れつく大きな事務所も門を構えているようだ。しかし、この区に住む労働者はその地理的・歴史的背景により多様化が進み、朝鮮や東南アジアや南米と言った多文化地域としての顔も持つ。そんなある種、日本の近未来を象徴とするような町に生きる人を本作では描いている。
 「川崎のこのひどい環境から抜け出す手段は、これまで、ヤクザになるか、職人になるか、捕まるかしかなかった。そこにもうひとつ、ラッパーになるっていう選択肢をつくれたかな」
 BAD HOP メンバーの T-pablow は言った。彼はテレビ番組の企画で十代のラッパーたちがフリースタイルで競い合う「高校生RAP選手権」で優勝したラッパーである。彼もまたラッパーとして若者の間で名を馳せる前、川崎にいる&amp;rdquo;捕まる系&amp;rdquo;の不良少年だった。本作で取材を受ける人たち、登場する人たちの多くは本当によく捕まる。そんな彼が取材で答えたセリフの中で印象に残ったものがあった。
 「オレらと同世代とか下の世代とかでやんちゃなヤツは、もともと、オレらの名前は知っていたと思うんですよ。そのへんはオレらが仕切ってたんで。逆に言うと、そいつらはオレらがどんな状況にいたのかも知ってる。だからこそ、ここまで来たっていうことが本当にすごいとわかるはずだし、それができるラップっていう表現が魅力的に見えたと思う」
 ちょっと前までは家にも帰らず夜な夜な悪さをしていたような少年が、家に帰らず他所で悪さをして歩くのではなく、夜な夜な公園にあつまり熱心にフリースタイルをやる、というほどにまで影響を与えていた。本作では、ラップという新しい風が川崎の少年少女の間を取り巻いて、少しでもディストピア・川崎サウスサイドに希望をもたらすものとして描かれている。
本作で大きく扱われているトピックとして、
 ラップ、ラッパー、ヒップホップがもたらした光 レイシズム系の問題、多文化地域が持つ闇 それに続くヘイトデモ 公営競技、風俗街、ドヤ街といった歓楽街に生きる人たち &amp;ldquo;川崎&amp;rdquo;の監獄に生きる少女  などが挙げられる。
もともと、連載による章立てでの取材ベースで話が進んでいる。しかし、出版にあたり大きく構成を見直した後にそれぞれのピースが他の章とリンクするような編纂が加えられており、ノンフィクションのルポルタージュでありながら、小説のように話のパズルがハマるような納得感があって読み応えがあった。 構成もさることながら、内容も上に述べたような話の比じゃないほどディープな取材、深層がブレイクダウンされていて、終始緊張感を持ちながら読み進められ一気読みしてしまった。今年読んだ本の中でもかなり面白く、&amp;rdquo;川崎&amp;rdquo;の今と過去、そしてそこにあった (そして一部は今もまだある) 事実をリアリティを持って知ることができるいい本だった。
とりあえず読んだほうが良い。</description>
    </item>
    
    <item>
      <title>Go から peco する</title>
      <link>https://tellme.tokyo/post/2018/04/25/go-finder/</link>
      <pubDate>Wed, 25 Apr 2018 02:11:37 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/25/go-finder/</guid>
      <description>peco とか fzf のようなフィルターコマンドが便利すぎて使わない日はないのですが、これらをどうしても Go プログラムに組み込んでしまいたいときが稀にあります。
どちらも Go で書かれているので、ライブラリとして使えるように提供されていれば import するだけなのですが、どちらも CLI (Command Line Interface) のみを提供しています。 CLI として作られている以上、シェルコマンドとして使うべきではあるのですが、そうすると何かと連携させたいとなった場合 (多くの場合はそうですが)、シェルスクリプトを書くことになります。 小さなものであればそれで構わないのですが大きめなツールになる場合、基本的にシェルスクリプトを書きたくないわけで、そうするとやはりどうしても Go から扱いたくなります。
シェルコマンドといっても CLI (Command Line Interface) なので、アプリケーションに精通したインターフェースである API (Application Programming Interface) と似たように考えることができて、CLI はコマンドラインに精通したインターフェースを持っているわけです。 そう考えるとコマンドのオプションはそのインターフェイスを通してコマンドに処理の変更を伝える起点と捉えることができます。
Go ではコマンドラインインターフェースとやりとりできる os/exec が標準パッケージとして使えるので、これをうまく使って CLI との通信部分を抽象化してラッパーライブラリとして実装できないか考えてみました。
https://github.com/b4b4r07/go-finder
go-finder というパッケージを作りました。
使い方は次のようになります。
finder - GoDoc
fzf, err := finder.New(&amp;quot;fzf&amp;quot;, &amp;quot;--reverse&amp;quot;, &amp;quot;--height&amp;quot;, &amp;quot;40&amp;quot;) if err != nil { panic(err) } fzf.Run()  peco, err := finder.New(&amp;quot;peco&amp;quot;, &amp;quot;--layout=bottom-up&amp;quot;) if err !</description>
    </item>
    
    <item>
      <title>golang でシェルの Exit code を扱う</title>
      <link>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</link>
      <pubDate>Mon, 02 Apr 2018 23:42:39 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</guid>
      <description>CLI ツールはよく golang で書く。 (golang でなくとも) ちゃんとした CLI ツールを書こうとすると、Exit code とそのエラーの取り回しについて悩むことが多い。 今回は、何回か遭遇したこの悩みに対する現時点における自分的ベストプラクティスをまとめておく。
ToC
 Exit code とは golang における Exit code 高次での取り回し  CLI 側 処理側  まとめ  Exit code とは $ ./script/something.sh $ echo $? 0  $? で参照できる値で、0 は成功を表し、0 以外は失敗を含む別の意味を表す。取りうる範囲は 0 - 255 (シェルによって違うことがあるかも知れない)。
$ true $ echo $? 0 $ false $ echo $? 1  詳しくは、コマンドラインツールを書くなら知っておきたい Bash の 予約済み Exit Code - Qiita
CLI ツールとはいわゆる UNIX コマンドであることが多いので、その慣習にならって実装するのよい。 成功したら 0 を、失敗したらエラーメッセージとともに非 0 を返すといった感じ。</description>
    </item>
    
    <item>
      <title>複数のサービスのヘルスチェックをとるツール</title>
      <link>https://tellme.tokyo/post/2018/04/01/req/</link>
      <pubDate>Sun, 01 Apr 2018 23:05:54 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/01/req/</guid>
      <description>ヘルスチェックのときの問題点 あるウェブサービスの動作確認をとっているとき、curl などを使ってリクエストを送ると思いますが、場合によっては環境変数が必要だったり、エンドポイントのパスが長かったり、Cloud IAP といった認証機構があったりします。 動作確認中はだいたい複数回実行するので実行しやすいように（また履歴で追いやすいように）、書き捨て用のシェルスクリプトにまとめたり、再利用しやすいようにワンライナーにしたりします。
#!/bin/bash GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; curl &amp;quot;https://iap-protected-app-url&amp;quot;  （再利用性が高く変数をスクリプト内のプロセスに閉じられる上に編集はしやすいが、毎回このようなシェルスクリプトを書くのは面倒）
$ GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; curl &amp;quot;https://iap-protected-app-url&amp;quot;  （再利用性も高く変数はコマンドのプロセスにしか影響しないが、長くて見づらく編集しづらい）
環境変数を含むワンライナーだとあまりにも長いので、以下のように環境変数の宣言部分だけコマンドラインから先に実行してしまえば curl と URL のみの実行で済みますが、特定のエンドポイント用の環境変数が実行シェルに記録されてしまうのは好ましくありません。
# 記録される $ GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; $ CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; $ curl &amp;quot;https://iap-protected-app-url&amp;quot;  （変数部分だけコマンドラインから定義してしまえば curl からの実行で済むが、シェルを再起動するまでは変数が実行プロセスに記録されてしまう）
問題はこれだけではありません。 開発環境の動作確認が終わったら本番環境の動作確認です（critical なサービスではない場合、初動の動作確認はカジュアルに curl でヘルスチェックを取ることも多いです）。
今度は本番環境に変わるのでURLや環境変数を書き換える必要があります。 また、開発環境と本番環境のヘルスチェックの行き来をしなきゃいけない場合もあります。 流石にここまでくると面倒くさくて、確認が終わったら削除するであろう取り急ぎなスクリプトにしちゃうことが多いです。
あとからまたヘルスチェックをとりたいと思ったとき これまでは上記の方法でなんとかお茶を濁していたのですが、最近厳しくなってきました。 見ているサービスが多くなってきたためです。
例えばあるサービスの Dev の様子がおかしいとなったとき、開発者が修正をデプロイしたとしても、場合によっては SRE や基盤チームがその後の疎通やサービスの状態をみたりします。 上にあるようなその場しのぎのスクリプトやワンライナーでやっていると、すでにスクリプトを削除していたり履歴を追うのが面倒で、こういうときにヘルスチェック用のパスが何だったのか（/health ? /status ?）、そもそもリクエストすべきサービスの URL がなんだったのか正確に思い出せません。
ツール https://github.com/b4b4r07/req
前に Cloud IAP で保護されたエンドポイントに対して簡単にリクエストを送るために作った CLI ツールの iap_curl が便利だったので、基本的な挙動はそのままに少し手を加えて汎用化しました。</description>
    </item>
    
    <item>
      <title>開いたファイルに対して ansible-vault を Vim から実行する</title>
      <link>https://tellme.tokyo/post/2018/01/31/vim-ansible-vault/</link>
      <pubDate>Wed, 31 Jan 2018 00:20:45 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/31/vim-ansible-vault/</guid>
      <description>生の何かをそのままリポジトリの置いておくのが微妙ということで特定のファイルを ansible-vault で暗号化してプッシュする、ということはよくあると思います。
例えば、Kubernetes の Secret を管理した YAML ファイルとかですね (例として正しいかは別の話ですが)。
その場合、こんな感じで暗号化する必要があります。
$ ansible-vault encrypt --vault-password-file=~/.vault_password secret.yaml  初回だけで済むならそこまで不便ではないのですが、このファイルを編集し再度リポジトリに上げるには復号と暗号化のセットも必要になります。 これがとても面倒です。 編集が必要ということは Vim なりのエディタで開くわけなので、そこでこのセットもいっぺんにできたら便利なわけです。
というわけで開いているファイル (バッファ) に対して ansible-vault (encrypt|decrypt) を実行するプラグインをつくりました。
 GIF イメージにある Credentials はサンプルです。
 filetype が ansible-vault であれば yes/no で復号するかどうか聞いてあげると、もう一手間省けるのでさらに便利な気もしますが、とりあえずの不便さは解消されたので現状使える Vim コマンドと機能はこれだけです。
 :AnsibleVaultEncrypt :AnsibleVaultDecrypt  便利になりました。
追記 (2018-10-25) chase/vim-ansible-yaml: Add additional support for Ansible in VIM
先行実装がありました。ただメンテが滞っておりメンテナーを募集しているみたいです。</description>
    </item>
    
    <item>
      <title>煉瓦の家</title>
      <link>https://tellme.tokyo/post/2018/01/16/renga_no_ie/</link>
      <pubDate>Tue, 16 Jan 2018 00:45:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/16/renga_no_ie/</guid>
      <description>はじめに 『煉瓦の家』は中島卓偉による通算15作目のオリジナルフルアルバム。デビュー15周年を記念してリリースされた前作の『BEAT&amp;amp;LOOSE』とは Vol.1、Vol.2 の関係性があり、Beatles でいうところの『Rubber Soul』と『Revolver』にあたる。
彼いわく Vol.1 と Vol.2 のセパレーションも自然に決まり、『BEAT&amp;amp;LOOSE』が完成した時点で、すでに本アルバムに収録されている15曲も概ねできていたという。
前作はギターが中心のアルバムで今作はベースが中心のアルバムになっている。 卓偉の中で1〜8曲目までがいわゆるA面、9〜15曲目までがB面になるように意識して制作されている。 また、今まで作ったアルバムの中で一番ブリティッシュ色の強いアルバムになっているとも。 本作の楽曲については基本、ギター・ベース・キーボードは全部卓偉が演奏し、14曲目の『東京タワー』についてはドラムも初チャレンジで演奏されている。
01. 大器晩成  Angerme に提供した一曲 本作では卓偉バージョンで収録 マイナーコードの3つをメインに使用してリフで展開し、メロディだけ変わっていくスタイル 洋楽テイストなチューン 彼いわく20代のころに書いているともっと長いイントロがついたかもしれないが、30代になり引き算の編曲ができるようになったからこそこんなテイストに落ち着いたという  02. 続けろ  シングルナンバーの1つ 今回のアルバム収録に合わせて、ミックスのバランスが変わったりしている 彼のスタイルでは先にシングルを作ってアルバムに入れるスタイルではなく、アルバム曲をすべてつくってからシングルカットするスタイルでやっている  が、曲が完成した時点で2曲目にすることが決まっていた というのもドラムから走るロック定番なチューンのため  アップテンポなエイトビートで展開する デビューしてから15、6年やり続けたことへの思いなどを歌詞にし、ブリティッシュなテイストに仕上げている  03. おまえは持ってる  作中で一番短い曲 中学3年のころに書いたいた古い曲 曲調はストレートなパンクナンバーでシンプルなアレンジ 曲自体は古くからあるがアルバム作成時の37歳の卓偉によるアレンジなどを加えてようやく今回アルバムに追加 すごく昔に書いた曲などをアレンジし直して入れるなども結構好き  04. 一人になろうとしないで  ポップなチューン 歌詞のままだがリスナーや人々を励ますような曲 メッセージソングになっている  05. 御城寺梨紗 〜all good idols go to heaven?〜  BEAT&amp;amp;LOOSE を知っている人はニヤッとするかもしれない曲 ちなみにタイトルは架空の人物 BEAT&amp;amp;LOOSE に収録されている『サイトウダイスケ』という曲のアンサーソング  前作のニュースの続きを読むような意味でアンサーソングになっている  サイトウダイスケに引き続き芸人のタイムマシーン3号に解説、詞の中でニュースを読んでいる  彼らのラジオに参加した際にタイムマシーン3号山本のアイデアでこのような形になった  Vol.</description>
    </item>
    
    <item>
      <title>2017年振り返り</title>
      <link>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</link>
      <pubDate>Fri, 05 Jan 2018 19:52:12 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/05/looking-back-on-2017/</guid>
      <description>もう年も変わってしまったけれど、去年どのような1年を過ごしたのかを振り返る。
1〜7月、SRE になったという記事でもある通り、環境や心境の変化もあってクォータの変わり目でもある7月のタイミングでチームを異動した。 それまでは JP チームでガイドだったり大型便向けの電話対応用の API を作ったり、配送周りで上がってくる問い合わせの技術対応をしていた。
少し戻って6月は、US アプリの刷新チームにてバックエンド API のサーバサイドエンジニアをやっていた。 入社からずっと JP のことをやっていたので、US に関わったのはとても新鮮だった。
7月、SRE になったのだけれど、まずなにをやるべきか、ということになった。 ちょうど全社的に Microservices 化に舵を切り出したころだったので、 「Microservices への技術転向を支える基盤づくりをする」SRE メンバーになることを当面の目標として、 そのために必要な技術の学習やキャッチアップを兼ねて、 社内ドキュメントツールとしてモノリシックに動いていた Crowi という Wiki サービスをコンテナ化して Kubernetes で構築してみることになった。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog  コンテナや Kubernetes、Spinnaker といった技術やツールを勉強しつつ、ミドルウェア自体のキャッチアップもこのときにやった。 仕事でありながら勉強できるという環境にあったので、とても貴重な体験だったかなと思う。 また、(今回は) Crowi という、
 Web アプリケーションを違うアーキテクチャに載せ替えるとしたときに考えるべきこと
 にフォーカスしながらミドルウェアの勉強ができたのもいい体験だった1。 各種ミドルウェア、ソフトウェアはそれぞれのマニュアルや技術書を読むことで得られるが、 システムに落とし込んで構成を組むときに思慮するというのは今までに経験がなかったのでよかった。
また、プライベートでははてなブログで書いていたブログをコンテナ化したり Kubernetes に載せたりして GKE の勉強をしていた (GCP のクーポンが切れたのでもう GKE には載っていない)。 ちなみにちょっとずつこっちにインポートしているが、以前のブログはまだ消してはいないので残っている。
 ブログをGKEで運用し、Spinnakerでデプロイする | tellme.</description>
    </item>
    
    <item>
      <title>2017年に購読したサービス</title>
      <link>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</link>
      <pubDate>Thu, 04 Jan 2018 20:32:44 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/01/04/subscribing-services-2017/</guid>
      <description>これらに便乗して。
  とりあえず昨年通して購読していて思い出せるものだけ列挙した。
購読したもの Amazon Prime 3,900円/年
Amazon で買い物するから。
Netflix 950円/月
映画、頻繁にみるので。
とにかく Breaking Bad はおすすめ。4周した。
http://www.breakingbad.jp/
アルバカーキに行ってロスポジョスエルマノスのチキンを食べたい。
Dropbox 12,000円/年
学生のときにヘビーに使っていたんだけど、いまはもうほとんどアクセスしていない。 オンラインストレージ自体に依存する生活をしていないので切っても良いのだけれど、昔のファイルなどを整理して移すのが面倒でそのままになっている。
GitHub 7ドル/月
ソフトウェアエンジニアなので。
https://github.com/b4b4r07
Education Plan が切れてしまい、使っていた Private Repo が Disabled になったので支払いとしては去年から。
iCloud 130円/月
50GB のプラン。iPhone のバックアップとして。今はまだ半分くらい。
写真などなどいちいち Mac にバックアップ、とか考えなくて良くなったから便利。 iPhone を新調したら「iCloud から復元」するだけで、さっきまで触ってた端末と同じ状態になる。
minikura 250円x複数個/月
購読サービスかと言われると違う気もするけれど、月額課金している便利なサービス。
使わないのに捨てられないもの (手紙、思い出の品) とかを預けている。 あとはシーズンではない洋服とか。
Apple Music 980円/月
Google Play Music、LINE MUSIC、Spotify、AWA、色々試したけどこれになった。 所持している Apple 製品が多いことが決め手だと思う。
HomePod が来たらもっと便利になると思っている。
Dartslive 315円/月
最近出たベータ版の黒いほうのアプリが超絶便利。 そのうち Phoenix も課金するかも。</description>
    </item>
    
    <item>
      <title>決済をキャッシュレス化している</title>
      <link>https://tellme.tokyo/post/2017/12/05/cashless/</link>
      <pubDate>Tue, 05 Dec 2017 08:57:17 -0600</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/05/cashless/</guid>
      <description>現状 キャッシュレスに切り替えて1年以上になる。 上京とともに現金を使うスタイルをやめた。 地方だと完全キャッシュレス化は現実的ではないが、首都圏、少なくとも都内23区においては現金を使うことなく生活できている。
よく使う決済手段は3つ。
 LINE Pay (JCB) ANA VISA Suica (VISA) モバイル Suica  他にもいくつかカードを持っているが、常用しているのは LINE Pay と ANA VISA Suica の2つで、電子マネーは Suica に絞っている。 ANA VISA Suica カードはややこしい名前だが Suica 機能 (オートチャージ設定可能) が付いた View カードで、ブランドが VISA になっている。
決済手段 LINE Pay JCB で1枚選出するとなると LINE Pay 一択かなと思う。 最高クラスの還元率 (2%) にも関わらず年会費などは不要で、コンビニなどですぐに買うことができる。 ほぼクレジットカードのように使うことができる1が、実態としてはプリペイドカード。 口座を指定しておくことで、LINE のアプリから24/7で入出金することができる。 最近はセブン銀行にも対応した2ことで、万が一キャッシュが必要になった場合、口座から LINE Pay に移して現金化するといったことも可能になった。
後述するがモバイル Suica と組み合わせると、「JCB は使えないが Suica は使える」というケースにおいてもポイントを取得することができる。
ANA VISA Suica 国内では JCB は VISA/MasterCard に遜色なく使える3が、海外だとあまり使えるところがない。 分散させるために違うブランドで、なおかつ待遇・特典のいいものを選んだ。</description>
    </item>
    
    <item>
      <title>Kubernetes 開発環境構築のいろは</title>
      <link>https://tellme.tokyo/post/2017/12/01/kubeabc/</link>
      <pubDate>Fri, 01 Dec 2017 00:54:11 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/12/01/kubeabc/</guid>
      <description>はじめに Kubernetes2 Advent Calendar 2017 - Qiita 1 日目です。
Kubernetes 上で動かすアプリを作ることが多くなってきていると思いますが、従来のオペレーションとは違う方法で開発やデプロイなどを行う必要があります。 Kubernetes の実行環境として GKE を例に取ると、GCP プロジェクトやその中で作った GKE クラスタ、Kubernetes ネームスペースなど、見る必要のある領域が増えるとともに今までのやり方も変わるはずです。 本記事ではその際のユースケースと、それをいい感じにしてくれるツールを紹介します。
今いるクラスタは何か 本番環境と開発環境 (Prod / Dev) でクラスタを分けることは多いと思います。 その他にもクラスタを持っていることもあるでしょう。
Continuous Delivery のプラットフォームとして Spinnaker が注目されつつあるので、Kubernetes クラスタへのデプロイはこれに置き換わる可能性1はありますが、Spinnaker がサポートしていない Kubernetes リソース (例えば、PodDisruptionBudget など) については、まだ手動で kubectl apply せざるを得ません。 また、基本的なリソースに対する apply 相当のことが Spinnaker によってできるようになったとはいえ、まだまだ手動で apply を実行したい場面もあります。 そこで気をつけたいのは、今いるクラスタとネームスペースの確認です。
Spinnaker は「デプロイ先のクラスタ」と「どのイメージを撒くか (manifest file)」をセットにして内部に持っているので「意図しないクラスタに対して意図しない manifest file をデプロイしてしまう」といった誤操作は防げるのですが、これが kubectl apply による手動だと今いるクラスタと -f に渡すファイル次第で、互い違いにデプロイしてしまうなどの事故も起こしかねません2。 毎回指差し確認するのも面倒ですし、そもそも確認を徹底するというのは有効打ではないので、常に見えるところに表示しておくのがおすすめです。
 手前味噌ですが、現在の Kubernetes クラスタと GCP プロジェクトを表示できるコマンドを書きました。</description>
    </item>
    
    <item>
      <title>SREになった</title>
      <link>https://tellme.tokyo/post/2017/11/02/sre/</link>
      <pubDate>Thu, 02 Nov 2017 01:33:34 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/11/02/sre/</guid>
      <description>最近、といっても今年の7月からですが SRE チームにジョインしました。
そもそも SRE とは Site Reliability Enginnering の略です。 Google が提唱しました。 国内ではメルカリがいち早くに改名したことでも知られています。
インフラチーム改め Site Reliability Engineering (SRE) チームになりました - Mercari Engineering Blog
ところで、今からおよそ1年前に入社エントリを書きました。
新卒でメルカリに入社した話 | tellme.tokyo
この頃ちょうど SRE 研修という名目のもと1ヶ月半ほど SRE チームにて業務の一端を担当しました。 研修という名を冠していますが、最前線にいる SRE から普通にタスクをもらって仕事したりレビューしてもらえるという、とても貴重な経験でした。 このときにインフラレイヤでのアーキテクチャ/ネットワークの設計や、実際に SRE が担っている業務領域に興味を持ち、このキャリアパスで飯を食っていきたいと思ったわけです。 無事に研修も終わり元のチームに戻ったわけですが、それ以降以前にもまして、SRE チームの動向ややりとりを羨望してました。
メルカリではクォータの変わり目や定期的な面談などで他分野への興味など広く技術のことについて話す機会があります。 そういった機会を利用しつつたびたびそれとなく話をしていた程度で、メルカリ SRE は技術力の高いチームであることもあり恐れ多くあまり声を大にしていなかったのですが、そうするうちに年も変わりたまたまあるきっかけを得ました。 それは &amp;ldquo;deeeet さんという人&amp;rdquo;が入社するっぽいぞという情報でした。 以前から尊敬するエンジニアのひとりだったのでひどく興奮したのを覚えています。
ときどき社内で話したり Go のイベントの手伝いや打ち上げなどで話す機会も多くなり、そのたびに「いつ SRE 来るんだ？」をいうジョブをもらい嬉しくも再度自分の思いを正しく伝えようと考えるきっかけになりました。 それからは上長や先輩たちに 1on1 をお願いし、今後自分がどうしていきたいのかなどを相談し、異動へのバックアップをしていただきました1。
晴れて今年の7月から SRE チームにジョインしたわけですが、チーム異動こそがゴールではないので、引き続きやるべきことをやっていく次第です。 直近では以下のようなことに手を出しつつ、Kubernetes を最大限に活用した Microservices 領域での基盤づくりなどを担当しています。
 メルカリ社内ドキュメントツールの Crowi を Kubernetes に載せ替えました - Mercari Engineering Blog Cloud Identity-Aware Proxy を使って GCP backend を保護する | tellme.</description>
    </item>
    
    <item>
      <title>Cloud Identity-Aware Proxy を使って GCP backend を保護する</title>
      <link>https://tellme.tokyo/post/2017/10/30/cloud-iap/</link>
      <pubDate>Mon, 30 Oct 2017 15:02:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/10/30/cloud-iap/</guid>
      <description>Cloud IAP とは  Cloud ID-Aware Proxy（Cloud IAP）は、Google Cloud Platform で動作するクラウド アプリケーションへのアクセスを制御します。 Cloud IAP はユーザー ID を確認し、そのユーザーがアプリケーションへのアクセスを許可されるかどうかを判断します。 - https://cloud.google.com/iap/
 つまり Cloud Identity-Aware Proxy (Cloud IAP、または IAP) を使うことで、任意の GCP リソース 1 に存在するロードバランサに対して、許可された Google アカウントやサービスアカウントによるアクセスのみに絞ることができます。 また、このアクセスリスト (ACL) の追加や削除などは GCP のウェブコンソールから簡単に制御することができます。
設定方法 GLB を作成する IAP を使う場合、GCP 上にロードバランサ (LB) を用意する必要があります。 これは IAP が LB に対して設定されるからです。
本記事では GKE、GCE での設定方法について説明します。 現時点で GAE にも対応していますが今回は検証しません。
1. GKE GKE で外部に公開したサービス (の Ingress) に対して ACL を設定したい、などでしょうか。 Ingress リソースを作成すると、自動で GLBC (GCE Load-Balancer Controller) が割り当てられます。 これは、GCP のウェブコンソールからも確認できます (メニュータブから Network services &amp;gt; Load balancing)。</description>
    </item>
    
    <item>
      <title>Software Design 2017年7月号に寄稿しました</title>
      <link>https://tellme.tokyo/post/2017/08/05/sd1707/</link>
      <pubDate>Sat, 05 Aug 2017 19:03:28 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/08/05/sd1707/</guid>
      <description>およそ1ヶ月ほど前に、Software Design 2017年7月号に寄稿しました。
すっかり告知や宣伝を忘れていたのですが、バックナンバーとしてまだ購入できるようですので、気になった方はお手にとっていただけると幸いです。
担当させていただいた章は、
 第2章：理論編2 シェルスクリプト初心者から中級者への次の一歩
 になります。
学生時代はよくシェルスクリプトを書いており、そのアウトプットのほとんどを Qiita やブログに載せていたため、今回このような形1で紙本になるのはとても嬉しかったです。
また機会があれば書かせていただきたいなと思います2。
  その記事をきっかけにオファーをいただきました [return] 需要があるかはわかりませんが、けじめをつけるためにも zplug の解説はどこかでしたいな、とは思っています (しかし掲載先は 1 人アドベントカレンダーのほうがいいかも知れませんね) [return]   </description>
    </item>
    
    <item>
      <title>ブログをGKEで運用し、Spinnakerでデプロイする</title>
      <link>https://tellme.tokyo/post/2017/07/30/blog-on-gke-deployed-by-spinnaker/</link>
      <pubDate>Sun, 30 Jul 2017 12:37:33 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/07/30/blog-on-gke-deployed-by-spinnaker/</guid>
      <description>このブログをはてなブログから Google Container Engine (GKE) に移行しました。
今回、移行先に GKE を選択した理由は GKE を使ってみたかったからです。ある Web サービスを GKE に移行することになったのですが、今まで Kubernetes を含め触ったことがなかったので、自分の持つサービスで練習がてらと思いブログを題材にしました。
目次
 移行のためにやったこと  ブログ用の Docker コンテナを作成 kubernetes cluster を構築 コンテナの入った Pod を動かす HTTPS 化する  記事の配信まで  Circle CI による継続的インテグレーション Spinnaker による継続的デリバリ  所感など  移行のためにやったこと 今回の移行に際し、移行周りのスクリプトや kubernetes のマニフェストファイル、及び記事自体を管理するために GitHub にリポジトリを作りました。
 1. ブログ用の Docker コンテナを作成 まずはブログを配信するためのサーバを載せたコンテナを作成します。静的サイトジェネレーターには Hugo を利用しました。
FROM golang:1.8-alpine AS hugo RUN apk add --update --no-cache git &amp;amp;&amp;amp; \ go get -v github.</description>
    </item>
    
    <item>
      <title>最強のヒストリ補完を作りました</title>
      <link>https://tellme.tokyo/post/2017/06/13/history/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/06/13/history/</guid>
      <description>最強のヒストリ補完を求めて シェルヒストリに不満を持っていたので自作しました。 今の自分にとっては必要な機能を盛り込んでいて便利に使えていますが、誰かにとっては、もしくは数カ月後の自分にとってはぜんぜん最強じゃないかもしれないです。
以前このようなエントリを書きました。
[http://www.tellme.tokyo/entry/2017/02/14/214231:embed:cite]
このころから (いやもっと前から) シェルのヒストリ補完に不満を持っていました。
 単純にデフォルトの C-r だと目的のものを探しづらい  例えばコマンド名の一部だけだとノイズが多すぎる けどディレクトリは覚えているからそれでもフィルタしたい、とか   他にも色々あって (その理由について先のエントリを見てもらうとして) zsh-history というツールを書きました。
https://github.com/b4b4r07/zsh-history
このときは最強のヒストリ補完ができたと、嬉々として先程のエントリを書いたのです。
しかし、まあ数ヶ月使っていると不便な点が見えてきて、
 複数ホスト間でもヒストリ共有したい ディレクトリだけではなくブランチごとに履歴を持ちたい カジュアルに履歴を消したい などなどの変更を加えるときに SQLite3 だとめんどい パフォーマンスは落ちるかもしれないけどテキストで持ってたほうが何かと便利かも  みたいなことが相まって作り直そうと思ったわけです。
新しく作った 特徴など 前回のネーミングセンスなさから変わらず、単に history となっています (そもそも前回のときのも zsh- prefix をつける必要性なかったので)。
 何ができるかというと、
 peco/fzf などでフィルタできる ブランチとかディレクトリに限定してフィルタできる (任意) 自動でバックアップしてくれる gist 経由で同期できる  GITHUB_TOKEN さえ渡せばよしなにやってくれるので、ユーザは他の PC でトークンを設定して history sync するだけ  同期のタイミングとか時間間隔とか差分量 (100 行以上で同期、など) の設定ができる 履歴を直接編集できる zsh intergrate は書いてるので source misc/zsh/init.</description>
    </item>
    
    <item>
      <title>Crowi 用の API Client 書いて公式に取り込まれた</title>
      <link>https://tellme.tokyo/post/2017/04/04/go-crowi/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/04/04/go-crowi/</guid>
      <description>Crowi というオープンソースソフトウェアの wiki があります。
 Markdown で書ける wiki で、
 Markdown をオートプレビュー URL (パス構造) でページを作成/表現できる リビジョンヒストリ (差分を管理してくれる) いいね、ブックマーク、ポータル機能、&amp;hellip;  などの特徴があって、とても便利なサービスです。
簡単に Heroku to deploy できるので気になる方は試してみてください。開発者向けにはオールインワンの Docker が有志によってメンテされているので、そちらを試してみても良いかもしれません。
go-crowi Crowi 用の API Client を Go で書きました。
https://github.com/crowi/go-crowi
Go で API Client は初めて書いたのですが、@deeeet さんの記事が参考になりました。
GolangでAPI Clientを実装する | SOTA
もともと、Qiita:Team からの移行ツールを Go で書いていたのですが、Crowi API と通信する部分は外部パッケージとして切り出したほうが汎用的に良いなと、go-crowi を作りました。
https://github.com/b4b4r07/qiita2crowi
このツールは Qiita:Team からのエクスポート用の JSON を食わすと、指定した Crowi に記事を作成してくれるものです。Qiita から画像を取ってきてアッタチメントしたり、コメントなども移行してくれます。
Transfer to Crowi そして今日、Crowi のメインメンテナの @sotarok さんから公式においても良いかも、というお話をいただき transfer しました。</description>
    </item>
    
    <item>
      <title>golang で zsh history を SQL 的に活用する</title>
      <link>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</guid>
      <description>僕は開発中、zsh のヒストリー補完の機能をよく使います。具体的には次のような場面が多いです。
 多用するコマンド  結局開発中に使うのはエディタ (vim) と git サブコマンドに集中する ちょちょいと ^N (↑) で履歴をさかのぼる  alias がイケてない場面  「エディタで .zshrc 開いて追加してリロード」が面倒で後回ししがち そして登録せずに終わる の繰り返し&amp;hellip; うろ覚え程度のコマンドの alias 名はもはや思い出せない 結局エディタ開いて見直したり、^R で遡ることに挑戦する  長いコマンド列になるとき  引数が多いとき、多段のパイプで繋いだとき 例えば、複数のパラメータを与えたときの curl コマンド   Ctrl-r (history-incremental-search-backward) よるヒストリーサーチが便利なのはよく知られたことですが、それに加えて peco のようなコマンドラインセレクタと zsh history を組み合わせて、過去に自分が入力したコマンドをその一部の記憶から引き出せるようにしたりして、便利になるようにカスタマイズしていました。
しかし、それでも以下のような不満がありました。
 ディレクトリごとに履歴を持ってほしい  ある特定のディレクトリでのみ使うコマンドなど git checkout ブランチ とか (git 系全般にいえる) プロジェクトのリポジトリとか tmux などで zsh を複数立ち上げているときなどにヒストリーを混同したくない  コマンド履歴にタグを付けたい  コメント (interactive_comments オプション) をつけて保持しておきたい あとあと検索が楽になる  すべての履歴を保持したい  何件まで保存、などは考えたくない 数年前の履歴も引き出せるようにしておきたい ただし数十万〜件になろうともパフォーマンスは落としたくない 標準のヒストリーは数十 MB にもなると、もたつく等の報告例あり  特定の月に使用したコマンド履歴を出したい  一定期間だけ違うプロジェクトにアサインされていたとか  substring search したい  これもディレクトリごとにできるとよし  history が壊れないような仕組みがほしい  突然壊れたとの報告例あり (自分は経験したことないけど) Twitter で検索すると嘆いている人が多い   zsh のオプション (setopt) や Third-party 系のプラグインなどを併用すれば一部の課題は解決できるのですが、同時に満たしてくれるものはなく自作しました。</description>
    </item>
    
    <item>
      <title>かゆいところに手が届く系の Git Tips 話</title>
      <link>https://tellme.tokyo/post/2016/12/20/git-tips/</link>
      <pubDate>Tue, 20 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/20/git-tips/</guid>
      <description>この記事は Git Advent Calendar 2016 の 20 日目です。git コマンドを日常的に実行するわけですが、外部スクリプトなどで個人的に日々改善しているお話についてまとめてみました。
ブランチ切り替えを手早くする git オペレーションで add,commit 並に多用すると思うのがブランチ切り替えで、特に remote にある branch の切り替えなどをショートカットしたくスクリプトを書きました。
$ git br  で fzf/peco などのフィルタで切り替えてくれます。ブランチ切り替え系はよくある tips なのですが、何が便利かというと、remotes/origin/HOGE などのリモートにしかないブランチは git checkout -b HOGE remote/origin/HOGE してくれるようになっているので気にせずに checkout できます。
詳しくは直接スクリプトを読んでみて下さい。簡単なシェルスクリプトです。
https://github.com/b4b4r07/git-br
ローカルのファイルを GitHub で読む hub browse です。認証しなくて良いので便利です。ブランチを指定するとそのブランチで開いてくれますし、省略すると現在いるブランチで開いてくれます。
$ git open  フォークして引数にファイル名を渡したら GitHub で開いてくれるようにしたのですが、まだマージされていません。が、僕のフォーク版だと、そのブランチのファイルを開いてくれます。
https://github.com/b4b4r07/git-open
大量のコンフリクトファイルを捌く 多人数で開発するとなると、ブランチ運用がマストなわけですがコンフリクトもまぁ発生するわけです。特に、DB の DNS 設定ファイルなどは同時に多人数が編集することも多く、衝突しやすいファイル群のように思います。解消するファイルが多数ある場合、修正して add するまでどれが完了したかいまいち分かりづらかったので、エディタで編集後にすぐ自動で任意の git コマンドを実行してくれるスクリプトを書きました。
https://github.com/b4b4r07/git-conflict
SSH に切り替える pull や push には HTTPS と SSH が選べると思いますが、SSH がいいときもあります。切り替えが面倒なのでこれを簡単にしました。git remote set-url し直すだけのスクリプトですが、長々とタイプしなくて良いので意外と便利です。</description>
    </item>
    
    <item>
      <title>実用 Slack bot ヤマト編</title>
      <link>https://tellme.tokyo/post/2016/12/12/yamato-bot/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/12/yamato-bot/</guid>
      <description>この記事は Slack Advent Calendar 2016 - Qiita の 12 日目です。
はじめに 最近のエンジニアは Slack に常駐していることが多くなってきたと思います。ゆえに bot が便利であることはご存知かと思います。受け取った文字列を echo する bot や、ランダムに画像を返す bot もその練習としてはいいですが、次のステップに bot を書くとしたら実用的なものを書きたいですよね1。
配送状況を通知する そこで書いたのが、荷物 (ヤマト) の配送状況が変わったら通知してくれる bot です。
 次のような機能を持ちます。
 bot yamato 追跡番号 とすると bot が追跡番号を監視するようになります 現在の配送ステータスを記憶するので変わったら通知してくれます  とりあえず、注文した荷物の追跡番号が発番されたら bot に向かって教えてやればよいです。すると bot は定期的に配送状況をチェックしてくれるようになります。
配送ステータスが変わると以下のように教えてくれるので、ユーザは荷物に対して受け身でいることができます。便利！
 まだ、積み残しも多いですがこれだけでも十分に便利でした。個人 Slack にでも通知してやりましょう。
謝辞 この bot では nanoblog さんによるヤマト運輸の配送状況を確認する API を使用しています。
 [WebAPI]ヤマト運輸の配送状況を確認するAPIを作ってみた [YamaTrack]ヤマト運輸の荷物問合せサイトを作成しました  終わりに この bot は Node.js で書いてます。Botkit のおかげでサクッと書けるのは良いのですが、デーモン化するにあたり forever を利用していると色々モヤることが多く、現在は Go 言語 (Supervisord) で書き直しています (本当は間に合わせるはずだった)。</description>
    </item>
    
    <item>
      <title>最近の Vim のプラグイン管理について考える</title>
      <link>https://tellme.tokyo/post/2016/12/05/2016-vim-plugin/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/05/2016-vim-plugin/</guid>
      <description>この記事は Vim Advent Calendar 2016 の 5 日目の記事です。
以前、neobundle.vim と vim-plug の比較記事を書きました。 それから数ヶ月後、dein.vim が登場し、再び比較記事を書こうと思っていたのですが、気づけばあれから 1 年が経っていました。 この記事は半年前 (&amp;lsquo;16年8月頃) に大枠だけ書き Qiita の限定共有に投稿していたのものを Advent Calendar 向けに書き下ろしたものです。
Vim プラグインの歴史 GitHub 以前 (〜2008年) 昔の話です。 Vim script で拡張の機能を書いたらそのスクリプトを vim.org にアップして開発者同士で共有したり、ユーザがダウンロードして使っていたようです。 おそらくコレが所謂「プラグイン管理」の始まりなのですが、このときはまだ手動で行われていたようです (残念ながら、このときはまだ Vim に出会っていなかったためその肌感は分かりません&amp;hellip;)。
例えば、こんな機能も Vim script で書いた拡張です (autogroup などは考慮してません)。
autocmd BufWritePre * %s/\s\+$//e  Vim 7 から Vimball という機能が Vim 本体に同梱されて、それからはこれを利用するユーザもいたようです。 vim.org からアーカイブされたスクリプトを持ってきて、:so % したり、気に入ったら runtimepath 以下に置いて自動読み込みしたり。 その頃の plugins ディレクトリは混沌としていたようです。 ペライチのスクリプトが無造作に転がっており、同名ファイルに気をつけたりアップデートの情報は自分でキャッチしなければなりませんでした。
GitHub 以降 (2008年〜) GitHub は 2008 年頃発のサービスですが、翌年には最大の Git のホスティングサービスになっていたようです。 本格的に流行りだしたのは 2011 年ころの印象を受けますが、このソーシャルコーディング時代の新風は Vim プラグイン界にも訪れ、席巻したようです。</description>
    </item>
    
    <item>
      <title>builderscon tokyo 2016 に参加してきました</title>
      <link>https://tellme.tokyo/post/2016/12/04/builderscon2016/</link>
      <pubDate>Sun, 04 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/12/04/builderscon2016/</guid>
      <description>引用
 buildersconは「知らなかった、を聞く」をテーマとした技術を愛する全てのギーク達のお祭りです
 tl;dr  builderscon tokyo 2016 に参加して、  裸で登壇された生 mattn さんを見て、 みんなを楽しませる技術力に凄いなぁと改めて思わされ、 自分も何か作りたい衝動に駆られた   Opening 牧さんによるオープニングでした。いきなり第2回開催予定の告知からスタートし会場が少しざわめきました。まだ、第1回の builderscon すら終わってないのに、このタイミングでの告知は、サプライズ感だけでなく絶対成功させるぞという気概を感じさせるとともに、コンセプトにもあるお祭りっぽさがあってとてもワクワクさせられました。
OSS は Windows で動いてこそ楽しい @mattn さんによる発表でした。僕ははじめてお目にかかりました。(見た目は) 普通以上に普通なのに、異常なエンジニアリング力です。改めて尊敬し直しました。Vimmer であり、時折 Go も書く自分としては一番楽しみにしていた発表でした。案の定、Go で Windows OSS 開発の未来が明るくなる話や、Vim の新作ネタプラグイン (畏敬の念を込めてネタプラグインと呼ぶ) などが発表されました。個人的に、Vim 界隈に長年貢献されてきた mattn さんと kaoriya さんのツーショットや、mattn さんの Vim 環境 (青っぽいリッチステータスラインに Solarized Dark なテーマ) を生で見られたことに感激しました。
php.ini について知る @uzulla さんによる発表でした。PHP を書くことが多くなった自分としては聞いときたいなと思い、聞いていたのですがやはり思った以上に知らないことが多く (PHP が ini を解釈するときは想像以上にゆるふわ) とても勉強になりました。&amp;quot;true&amp;quot; って true じゃないとか、ini ファイルのパス解決順序で最後に読まれた ini が適用されるので気づかないでハマってたり、なんかつらそうだという印象でした。良くも悪くもそこが PHP の特徴なところもあるようで、うまく折り合いながら向き合っていく気合が必要とのことでした。発表終了間際に発言されていた「php.</description>
    </item>
    
    <item>
      <title>運営として VimConf 2016 に参加してきた</title>
      <link>https://tellme.tokyo/post/2016/11/06/vimconf2016/</link>
      <pubDate>Sun, 06 Nov 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/11/06/vimconf2016/</guid>
      <description>株式会社ミクシィさんにて行われた VimConf 2016 の参加レポートです。自分は一般参加者としてではなく、一部運営に携わったのでその点について主に書ければなと思います。
tl;dr   VimConf 2016 のまとめ役として参加しました スライドの感想や資料については他の方のレポートを見てください 「ババロットさん、アイコン変えた方がいいよ」  まとめ役として参画した背景 ある日突然、社内 Slack の個人チャンネル (分報的なアレ) にてこんなポストが投げられました (リンクだけ)。
  二つ返事で参加レスをしたわけですが、これはノリで運営やってみました、とかでは全くないです。日々、Vim を使い vim-jp やその界隈の人たちのプラグインなどを使ったりし感謝していくうちに、いつかコミュニティに携わりたい・還元したいという気持ちが芽生えていたためです。たまたまこの煽りポストがいい後押しとなり、運営への参画を踏み出すきっかけになったのでした。
ひとり KPT まとめ役という肩書きで参加したわけですが、色々振り返ってみるとやり残したことや課題感、続けたいことなどが見えたのでまとめてみます。
 KEEP  VimConf 2017 への参画  せっかく自分の中に溜まったノウハウをここで途絶えさせるのは勿体無いので、次回も何らかの形で携わりたい。貢献し続けることも大切  参加率の良さ  9 割近くの参加率、総勢約 120 名での VimConf は初のこと。募集開始を遅らせたりなどの工夫があった。果たしてこれが功を奏したかは来年も試してテストしてみないとだけど  ケータリングの量  多すぎず少なすぎずで懇親会終わる頃にちょうど綺麗になくなった感。廃棄もほとんどなかったんじゃないかな。ここは自分ががっつり噛んでいたところなので見事な新卒力を発揮できた  交流が活発に見えた  誰とも話せない、という人はいなかった気がします。それとドリンク島がドリンクを求めた立ち寄った人との交流の場になっていたのは良かった   PROBLEM  コミットが足りなかった  TRY: 忙し月と準備が被った。次回も参加することで乗り越えていきたいところ  意外とバタバタ@懇親会準備1  TRY: 各種業者に当日リマインダを掛けられたのはよかった。ただ、一部到着連絡をもらえず開場まで運ばれたのには焦った (受付に人がいて気づいてくれた. いなかったらと思う図ちょっとゾッとする)。  意外とバタバタ@懇親会準備2  TRY: 皿や紙コップ、醤油や小皿のデプロイに手間取った。これは前々からその準備が必要だなって思った。発表中にごそごそするわけにもいかないだろうし。    印象に残ったこと # TODO: ババロットさんに中年エンジニアと誤認していたことを謝る。https://t.</description>
    </item>
    
    <item>
      <title>特定のワードで Twitter を監視して、検知したら Slack に投げる</title>
      <link>https://tellme.tokyo/post/2016/10/17/twistd/</link>
      <pubDate>Mon, 17 Oct 2016 00:24:32 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/10/17/twistd/</guid>
      <description>&amp;hellip; というツールを書きました。 Twitter Streaming Daemon なので twistd です。 最近話題の名前衝突ですが、こっちは個人のツールだし一旦気にしないことにします (リポジトリ作ってから気づいた)。
 tl;dr  Twitter Streaming API を利用してツイートを監視する 特定のワードで引っかかったら Slack に通知する 2つをいっぺんに行うコマンドを書いた (デーモンとして利用しましょう)  
※ [&#39;tomato&#39;, &#39;potato&#39;] で引っ掛けてる例
モチベーション zplug (GitHub Organization) ではオーナーの他に数名のコラボレーターの方たちがいます。 開発者同士のコミュニケーションには Slack を用い、GitHub Issues で issue トラッキングをしています。 Slack への GitHub の通知は、Slack のインテグレーション機能 (issue が作られたり P-R が投げられると通知される) を使っています。 これはよくあるスタイルだと思います。
ところが、数ヶ月 Organization を運用して気づいたのが GitHub Issues に上がってこないバグレポートや機能改善、機能要望も結構あるということです。 その多くは Twitter 上でつぶやかれていて、それからは時折 zplug -RT とかで Twitter 検索をしていたのですが、それを他のコラボレーターに共有するのが面倒なことと、定期的なエゴサーチが面倒 (見逃すということもある) で、Twitter を常時監視して zplug についてつぶやかれていたら Slack にポストしてくれるツールはないかと探しておりました。 ちょうど良さそうなツールはないようなので作ることにしました。</description>
    </item>
    
    <item>
      <title>新卒でメルカリに入社した話</title>
      <link>https://tellme.tokyo/post/2016/10/01/mercari/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/10/01/mercari/</guid>
      <description>タイトルの通りです。 16年卒の学部卒新卒として株式会社メルカリに入社しました。 入社したのは今年の 4&amp;frasl;1 なので半年前のことです。 なぜ今頃になって入社エントリを書くのかというと、先日新しいメディア立ち上げにともなう記事一発目としてインタビューを受けたのですが、その記事が 10&amp;frasl;3 に公開されるとのことで、他者に明らかにされるならばその前に自分から入社エントリを書こうと思ったことと、タイミング的にも今日という日はちょうどいいなと思ったからです。
tl;dr  新卒でメルカリに入社しました メルカリでは新卒採用もしているので興味があれば言ってください  メルカリという会社  https://www.mercari.com
メルカリが新卒採用を始めたのは今年からなので、僕は第一期新卒ということになります。 最近ではとても有名なアプリ・会社になってきて、国内での勢いはもちろんのことアメリカでも急成長してきており、今後の動向にワクワクしつつ日々携わっております。
16 新卒は 6 人いて、今は 17&amp;frasl;18 卒の新卒採用に向けて動いています。 採用会食など、まずは話から聞いてみたいなという方がいましたら、僕経由で繋ぐことができるかもしれませんので興味があれば Twitter DM でもいいですし、コンタクトいただければなと思います。 新卒・中途採用どちらでも OK ですし、時期に関しても関係ないと思います（次の新卒がこの時期に連絡しても問題ないのかという意味で）。
入社までの経緯 プログラミングといえるようなことは大学に入ってからはじめました。 C 言語の開発環境 (bash on Linux) に慣れなかったことから、色々改善しようと .bashrc のカスタマイズにのめり込み、シェルスクリプトを覚えるようになりました。 同時に Emacs に慣れずにエディタには Vim を使うようになり、同じく .vimrc のカスタマイズ (Vim script) にハマりました。 夢中になって気づいたら朝ということも何度かあった気がします。
もともと、Windows を使っており、当時 AutoHotkey と超低機能 2 画面ファイラの「あふｗ」 (敬意を込めて) のカスタマイズにハマっていたことから、Linux でのカスタマイズについても夢中になることは明白でした。 これを機にと macOS (当時の表記で言う Mac OS X。 途中から OS X) に乗り換えたことで、更にそれは加速したような気がします。 しかし、シェルスクリプト力とエディタ力は上がれど、なかなか他の言語を集中して覚えることがなく、しばしば悩んでおりました。</description>
    </item>
    
    <item>
      <title>最近、httpstat なるものが流行っているらしい</title>
      <link>https://tellme.tokyo/post/2016/09/25/httpstat/</link>
      <pubDate>Sun, 25 Sep 2016 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/09/25/httpstat/</guid>
      <description>おそらく先行実装は python で書かれたこれです。
  curl にはウェブサイトの応答時間を計測する機能が搭載されており、このツールではそれを利用して出力結果をグラフィカルに表示させています。 単なる curl のラッパーのようなツールなのですが、見た目がリッチになるのに加えて、単一ファイルで実行でき python のバージョンに影響されないような工夫がされているのが、受けているポイントのような気がします。
このツールを見たとき「Go で書いてみるの良さそう！（この手のツールで単一バイナリになるのは嬉しいですよね）」と思い、休憩時間やお昼休みなどにちまちま書いていたら、二日前に先を越されてしまいました（そりゃそうですよね。なんでもスピードが大事だと痛感）。
  また、ついこの間まで 800 Stars くらいだったのですが、ここ1週間で爆発的に伸びています（記事投稿時 1,100 Stars）。 これを機になのか、色々な実装を見るようになりました。知らないだけで他にもあるかもしれません。
 yosuke-furukawa/httpstat (JavaScript) tcnksm/go-httpstat (Go package) talhasch/php-httpstat (PHP)  Go で先を越され少し悔しい気もするので、curl のラッパーだしシェルスクリプトでも書いてみようと思い、書いてみました。 なんのメリットがあるかは分かりませんが、bash オンリーで書いているので bash のある環境であれば動くはずです。
 次に時間があるときは Vim script で書こうかな。</description>
    </item>
    
    <item>
      <title>ほんの 1分で GitHub に公開鍵を登録して SSH 接続する</title>
      <link>https://tellme.tokyo/post/2015/11/11/ssh-keyreg/</link>
      <pubDate>Wed, 11 Nov 2015 00:36:02 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/11/11/ssh-keyreg/</guid>
      <description>公開鍵認証はとても便利ですが、他のマシンに移ったり Vagrant などで仮想開発環境をつくったときなど GitHub に公開鍵をアップロードするの面倒ではないですか？
ssh-keygen で作成された 公開鍵.pub の中身をコピーしてブラウザに貼り付けて ssh -T git@github.com できるかチェック．．．
面倒なので簡略化したプラグインをつくりました。利用者が打ち込むコマンドは以下のみです。
$ # (antigen bundle b4b4r07/ssh-keyreg) $ ssh-keygen $ ssh-keyreg  はやい！！！

 b4b4r07/ssh-keyreg - GitHub  上では、antigen でインストールすると書いていますが、このプラグインは bash でも動きます（補完は zsh のみです。ごめんなさい）。
インストール $ # for zsh $ antigen bundle b4b4r07/ssh-keyreg $ # for bash $ sudo sh -c &amp;quot;curl https://raw.githubusercontent.com/b4b4r07/ssh-keyreg/master/bin/ssh-keyreg -o /usr/local/bin/ssh-keyreg &amp;amp;&amp;amp; chmod +x /usr/local/bin/ssh-keyreg&amp;quot;  使い方 $ ssh-keyreg usage: ssh-keyreg [-h|--help][[-d|--desc &amp;lt;desc&amp;gt;][-u|--user &amp;lt;user[:pass]&amp;gt;][-p|--path &amp;lt;path&amp;gt;]] [github|bitbucket] command line method or programmatically add ssh key to github.</description>
    </item>
    
    <item>
      <title>HTTP のステータスコードを簡単に調べる</title>
      <link>https://tellme.tokyo/post/2015/11/07/http_code/</link>
      <pubDate>Sat, 07 Nov 2015 00:32:23 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/11/07/http_code/</guid>
      <description> HTTPステータスコードは、HTTPにおいてWebサーバからのレスポンスの意味を表現する3桁の数字からなるコードで、RFC 2616、RFC 7231等によって定められている。via HTTPステータスコード - Wikipedia
 403とか404はよく目にもするので覚えていますが、300番台は？500番台は？とかとなると思い出せないことが多いです。 いちいちググり直すのも手間。 そんなときに、bash なりのシェルにてエイリアスとして登録しているハックを目にしました。
 Jxck/dotfiles - GitHub  このまま参考にさせてもらおう、と思ったのですがすべて登録するのもな、と思いコマンドで用意しました1。

 b4b4r07/http_code - GitHub  antigen で簡単にインストールできます。
$ antigen bundle b4b4r07/http_code  antigen でない場合は、
sudo sh -c &amp;quot;curl https://raw.githubusercontent.com/b4b4r07/http_code/master/bin/http_code -o /usr/local/bin/http_code &amp;amp;&amp;amp; chmod +x /usr/local/bin/http_code&amp;quot;  しかし、antigen でインストールしたほうが、補完ファイルなども使用できるようになります。
使い方は gif アニメにもある通り、-a/--all オプションをつけると一覧表示、引数に数字を渡すとそれに対する説明を返します。
 番号が変わるものでもないので一度登録して変更することになる心配がないためエイリアスもいいと思います [return]   </description>
    </item>
    
    <item>
      <title>MacBook 12 inch を買った</title>
      <link>https://tellme.tokyo/post/2015/08/14/macbook/</link>
      <pubDate>Fri, 14 Aug 2015 00:57:24 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/08/14/macbook/</guid>
      <description>来ました pic.twitter.com/nwUUZSogN6
&amp;mdash; BABAROT (@b4b4r07) May 20, 2015 
 5&amp;frasl;20 に「新しい MacBook」が届いた．Apple のオンラインの Store で，実際にポチったのは4/12なので届くのには1ヶ月以上かかったことになる．
スペックはこの通りだ．
 CPU を最大の 1.3GHz に引き上げた．処理スピードは速いに越したことはない．それと，ここに載っていない変更点として，キーボードを US 配列にした．これはデザイン的な動機もあるが，主として私の用途がプログラミング関連だからだ．デスクトップ PC にも US 配列のキーボードを使用している．
 Why なぜ，この賛否両輪ある新しい無印の MacBook を買ったかというと，それまで使っていた MacBook Air (13 inch, Mid 2012) に不満が溜まってきていたからだ．
 13インチはモバイル機としては大きすぎる メモリが 4GB（初のモバイル Mac だったため勝手がわからなかった） キーボード（特にスペースキー）の反応が悪くなり始めた MacBook がかっこ良すぎた  上2つが特に大きな動機だった．MacBook が発表される前，一度 MacBook Air 11 inch を検討していたくらいに軽さ・小ささを求めていた．
以前，iPad（Airの前）を所有していた．買った当初は頻繁に持ち歩いていたもの，その重さや大きさからか徐々に持ち運ばなくなっていた．そこで，それを売っぱらって iPad mini を買うことにした．iPad mini にしてからは持ち歩くことが増え，また片手でひょいと持ちやすかったため，トイレやらキッチンやら隙間時間を生み出しそうなところには常に連れ歩いた．この携帯性がノート PC にも欲しかった．出かけるとき，ひょいと「PC 使うかわかんないけど持っていくか」となりたかったのだ．
いざ買ってみて 満足か，後悔か．もちろん大満足である．とにかく軽くて小さい Mac PC（UNIX 端末）が欲しい人にはピッタリなノート PC だと思う．賛否両論あるポイントを中心にレビューしてみる．</description>
    </item>
    
    <item>
      <title>dotfiles を curl -L dot.hoge.com | sh でインストールする方法</title>
      <link>https://tellme.tokyo/post/2015/01/18/curl-sh-install/</link>
      <pubDate>Sun, 18 Jan 2015 00:39:49 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2015/01/18/curl-sh-install/</guid>
      <description>dotfiles をインストールする際に、
$ curl -L https://raw.githubusercontent.com/{YOUR_ACCOUNT}/dotfiles/master/install.sh | bash  といった具合にウェブを介してスクリプトを実行することが一般的になりつつあると思いますが、この方法にはひとつ問題がありそれは URL 部分が長いということです。これは結構厄介で長すぎるがゆえに暗記できないので、いちいちブラウザを起動してコピペしないといけなかったり、そもそもブラウザなどないようなどこかのサーバにデプロイするときなど、暗記していたほうがいい場面が結構あります。
 curl -sL dot.hoge.com | sh で自分専用環境を構築する方法（かっこいい）
 そんなとき、このエントリを発見しました。 独自ドメインを取得して、そのサブドメインに自分で立ち上げた Nginx で dotfiles リポジトリへリダイレクトしてやるようにする方法です。こうすることで、github の URL 部分を自分のドメインを使った好きな URL にすることができるようになります。
しかし、この方法はサーバと独自ドメインの2つを用意しなければなりません。エンジニアたるものサーバやドメインは持っていたほうがいいのかもしれませんが、持っていなかった場合 dotfiles の URL 短縮のためだけに維持費に数千円／年を支払うのはもったいないですよね。
そこで、利用するのが短縮 URL サービスです。最近ではとても身近なものになり、スタンダードになりつつある Bitly をはじめ Amazon 専用の amzn.to や Google の goo.gl などとても増えてきています。
その中でも、今回はカスタムドメインを指定できる Bitly を使用します。これでリダイレクトさせるウェブページを作成する必要がなくなり、サーバ代を浮かすことが出来ます（注：ただし独自ドメインは取得する必要があります）。
事前準備 独自ドメインの取得  ムームードメイン お名前.com  有名どころですとサクッと取得することができます。 個人情報を入力し、年額を支払い、振込が確認された後、認証まで数時間たつとドメイン取得となります！
 ここらへんは100円／年台からなのでとても安価です。
Bitly アカウント作成 無料アカウントを作成します。最近までは Bitly Pro という有料サービスでカスタムドメインの設定を提供していましたが、今では無料アカウントに開放しています。
カスタムドメインの設定 さて、ここからが本番です。ここからは筆者の環境（ ムームードメイン）で説明していきます。 ムームードメインのサイトにいき、</description>
    </item>
    
    <item>
      <title>Vim からシェルコマンドを実行するプラグインを作った</title>
      <link>https://tellme.tokyo/post/2014/10/05/vim-shellutils/</link>
      <pubDate>Sun, 05 Oct 2014 00:52:51 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2014/10/05/vim-shellutils/</guid>
      <description>Vim の魅力の1つにシェルとの親和性が挙げられます。 GUIじゃない Vim を使っている時にどうしてもさっと ls したかったり、さっとファイルの中身を cat してみたかったりしたときに、Vim を終了したくない、なんてことはありませんか。 Ctrl-z で Vim を中断し、コマンドをタイプし処理して戻ってきた頃には、「あれ、、、なんだったっけ」なんてこともしばしば。 思いつきやアイデアは1分1秒が大事なのです。
そこで Vim のコマンドライン領域からシェルコマンドもどきを実行できるプラグインを作成しました。 もどきと書いたのは call system() や !command の類を使用しないためです（シェルコマンドをエミュレート）。 どちらもシェルのコマンドに依存する上に一時的に Vim 画面が切り替わったり、あまり挙動が好みではありませんでした。 そこで純 Vim script で作成することで Vim さえあればシェルコマンドを実行出来るようにしました。
詳しくは、
 README.md doc/shellutils.txt  をご覧ください。</description>
    </item>
    
  </channel>
</rss>