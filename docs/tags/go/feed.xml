<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Go on tellme.tokyo</title>
    <link>https://tellme.tokyo/tags/go/</link>
    <description>Recent content in Go on tellme.tokyo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <copyright>BABAROT All Right Reserved.</copyright>
    <lastBuildDate>Tue, 19 Feb 2019 21:40:24 +0900</lastBuildDate>
    
	<atom:link href="https://tellme.tokyo/tags/go/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kubernetes などの YAML を独自のルールをもとにテストする</title>
      <link>https://tellme.tokyo/post/2019/02/19/test-kubernetes-yaml/</link>
      <pubDate>Tue, 19 Feb 2019 21:40:24 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/19/test-kubernetes-yaml/</guid>
      <description>設定ファイルのメンテナンスの必要性 Infrastructure as Code の普及もありインフラの状態やその他多くの設定が、設定ファイル言語 (YAML や HCL など) で記述されることが多くなった。 Terraform HCL や Kubernetes YAML など、人が継続的にメンテナンスしなければならなく、その設定が直接プロダクションに影響を与える場合、そのレビューがとても重要になる。 具体的に例えば、「デプロイする Replica の数」や「Resource limit や PodDisruptionBudget が適切か」などレビューの中で注意深く見なけれなならない点などがあげられる。 加えて日々のレビューの中で、問題にはならないが「Kubernetes の metadata.namespace は省略できるけど事故防止の意味も込めて明示的に書きましょう」といった設定ファイルに対して強制させたいポリシーなどが生まれて、ひとつのレビュー観点になっていくことは自然である。
人がレビューの中で毎回見なければならないこと、毎回指摘すること、機械的にチェックできることはルールセットを定義して、それをもとに lint でチェックして CI で失敗させるのが効率的である。
YAML などのただの設定ファイル言語に対して「独自のルールを定義してそれをもとにテストする」ということは実は難しかったりする。
 garethr/kubeval: Validate your Kubernetes configuration files, supports multiple Kubernetes versions viglesiasce/kube-lint: A linter for Kubernetes resources with a customizable rule set  kubeval はマニフェストファイルの validator として機能する。例えば、integer として定義しなければいけないフィールドを string で定義していた場合に検知することができる。 kube-lint は決められた Kind (現在は Pod のみ) の決められたフィールドのチェックを決められたオペレータ (equal, not equal など) で違反していないかチェックすることができる。</description>
    </item>
    
    <item>
      <title>hashicorp/hcl2 を使って独自 DSL を定義する</title>
      <link>https://tellme.tokyo/post/2019/02/19/hashicorp-hcl2/</link>
      <pubDate>Tue, 19 Feb 2019 02:44:36 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/19/hashicorp-hcl2/</guid>
      <description>HCL2 とは HCL (HashiCorp Configuration Language) は HashiCorp によって作られた設定言語です。 HCL の目的はコマンドラインツールで使用するために、人間からも機械からも扱いやすく構成されていて、かつ特に DevOps ツールやサーバーなどを対象とした構造化構成言語であることです。
実装は hashicorp/hcl にあります。
実はこれの他に同時に Version 2 の実装も目下開発中のようです。
hashicorp/hcl2: Temporary home for experimental new version of HCL
このリポジトリでは HCL が元から持つ iteration と補間言語 HIL を組み合わせて、任意の式をサポートする単一の構成言語を目指しているようです。 要するに、設定ファイルでありながら、演算処理や式の評価といったプログラミング言語的な要素を持ち合わせます。
ちなみに、HCL は HCL2 との互換性は保証されていないため、application から使用する場合は latest ではなく vendoring したものを参照するのが好ましいです。 また、HCL から HCL2 への移行パスは想定されていないようです。 構文の見た目上は非常に似ておりベースデザインは元実装を引き継ぎつつも、拡張された部分については全く異なるアプローチで実装されているようです。 例えば HCL2 の実装の方はより堅牢なエラー処理を可能にする機能などが盛り込まれています。 HCL2 の開発が安定したらもとのリポジトリはアーカイブされ、こちらが HCL の本実装になるようです。
ちなみに、HCL2 を含んだ HCL 全体のデザインなどは次の PDF が参考になります。
HCL Documentation
HCL2 の機能 JSON や YAML のパーサでは、バイト列を Go の構造体に落とし込むことで各要素を Go プログラム内から扱えるようにしています。</description>
    </item>
    
    <item>
      <title>Go のコマンドラインツールを簡単にリリースする</title>
      <link>https://tellme.tokyo/post/2019/02/15/release-go/</link>
      <pubDate>Fri, 15 Feb 2019 01:09:19 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2019/02/15/release-go/</guid>
      <description>goreleaser のおかげで Go のバイナリをクロスプラットフォーム向けにビルドしてパッケージングして GitHub Releases にアップロードするステップがだいぶ簡単になった。
今までは、gox + ghr などを使ってそれらをスクリプト化したものを各リポジトリに用意する必要があったのが、今では goreleaser 用の設定ファイル (YAML) を置くだけでよくなった。
例: stein/.goreleaser.yml at master · b4b4r07/stein
しかしそれでもリリースするにあたっていくつかのプロセスが残っている。
 tag 打ち バージョン情報の更新 Changelog の更新  それらをスクリプト化して各リポジトリに置くと、スクリプトに改修や機能追加すると各リポジトリでアップデートしなきゃいけなかった。自分向けなので必ずやらなきゃいけないわけではないけど、毎回シェルスクリプトを書くのも億劫だし、git.io を使って共用できるようにした。
b4b4r07/release-go
使い方は簡単で raw のスクリプトを curl などで取ってきて bash にわたすようにする。
実際は Makefile なんかに書いておくとより便利になる。
.PHONY: release release: @bash &amp;lt;(wget -o /dev/null -qO - https://git.io/release-go)  これを実行すると、
 gobump を使って semver 形式で bump up git-chglog を使っている場合は Changelog の更新 goreleaser の実行  を必要に合わせてプロンプト経由で対話的に実行することができる。</description>
    </item>
    
    <item>
      <title>Go から peco する</title>
      <link>https://tellme.tokyo/post/2018/04/25/go-finder/</link>
      <pubDate>Wed, 25 Apr 2018 02:11:37 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/25/go-finder/</guid>
      <description>peco とか fzf のようなフィルターコマンドが便利すぎて使わない日はないのですが、これらをどうしても Go プログラムに組み込んでしまいたいときが稀にあります。
どちらも Go で書かれているので、ライブラリとして使えるように提供されていれば import するだけなのですが、どちらも CLI (Command Line Interface) のみを提供しています。 CLI として作られている以上、シェルコマンドとして使うべきではあるのですが、そうすると何かと連携させたいとなった場合 (多くの場合はそうですが)、シェルスクリプトを書くことになります。 小さなものであればそれで構わないのですが大きめなツールになる場合、基本的にシェルスクリプトを書きたくないわけで、そうするとやはりどうしても Go から扱いたくなります。
シェルコマンドといっても CLI (Command Line Interface) なので、アプリケーションに精通したインターフェースである API (Application Programming Interface) と似たように考えることができて、CLI はコマンドラインに精通したインターフェースを持っているわけです。 そう考えるとコマンドのオプションはそのインターフェイスを通してコマンドに処理の変更を伝える起点と捉えることができます。
Go ではコマンドラインインターフェースとやりとりできる os/exec が標準パッケージとして使えるので、これをうまく使って CLI との通信部分を抽象化してラッパーライブラリとして実装できないか考えてみました。
https://github.com/b4b4r07/go-finder
go-finder というパッケージを作りました。
使い方は次のようになります。
finder - GoDoc
fzf, err := finder.New(&amp;quot;fzf&amp;quot;, &amp;quot;--reverse&amp;quot;, &amp;quot;--height&amp;quot;, &amp;quot;40&amp;quot;) if err != nil { panic(err) } fzf.Run()  peco, err := finder.New(&amp;quot;peco&amp;quot;, &amp;quot;--layout=bottom-up&amp;quot;) if err !</description>
    </item>
    
    <item>
      <title>golang でシェルの Exit code を扱う</title>
      <link>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</link>
      <pubDate>Mon, 02 Apr 2018 23:42:39 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/02/golang-shell-exit-code/</guid>
      <description>CLI ツールはよく golang で書く。 (golang でなくとも) ちゃんとした CLI ツールを書こうとすると、Exit code とそのエラーの取り回しについて悩むことが多い。 今回は、何回か遭遇したこの悩みに対する現時点における自分的ベストプラクティスをまとめておく。
ToC
 Exit code とは golang における Exit code 高次での取り回し  CLI 側 処理側  まとめ  Exit code とは $ ./script/something.sh $ echo $? 0  $? で参照できる値で、0 は成功を表し、0 以外は失敗を含む別の意味を表す。取りうる範囲は 0 - 255 (シェルによって違うことがあるかも知れない)。
$ true $ echo $? 0 $ false $ echo $? 1  詳しくは、コマンドラインツールを書くなら知っておきたい Bash の 予約済み Exit Code - Qiita
CLI ツールとはいわゆる UNIX コマンドであることが多いので、その慣習にならって実装するのよい。 成功したら 0 を、失敗したらエラーメッセージとともに非 0 を返すといった感じ。</description>
    </item>
    
    <item>
      <title>複数のサービスのヘルスチェックをとるツール</title>
      <link>https://tellme.tokyo/post/2018/04/01/req/</link>
      <pubDate>Sun, 01 Apr 2018 23:05:54 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2018/04/01/req/</guid>
      <description>ヘルスチェックのときの問題点 あるウェブサービスの動作確認をとっているとき、curl などを使ってリクエストを送ると思いますが、場合によっては環境変数が必要だったり、エンドポイントのパスが長かったり、Cloud IAP といった認証機構があったりします。 動作確認中はだいたい複数回実行するので実行しやすいように（また履歴で追いやすいように）、書き捨て用のシェルスクリプトにまとめたり、再利用しやすいようにワンライナーにしたりします。
#!/bin/bash GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; curl &amp;quot;https://iap-protected-app-url&amp;quot;  （再利用性が高く変数をスクリプト内のプロセスに閉じられる上に編集はしやすいが、毎回このようなシェルスクリプトを書くのは面倒）
$ GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; curl &amp;quot;https://iap-protected-app-url&amp;quot;  （再利用性も高く変数はコマンドのプロセスにしか影響しないが、長くて見づらく編集しづらい）
環境変数を含むワンライナーだとあまりにも長いので、以下のように環境変数の宣言部分だけコマンドラインから先に実行してしまえば curl と URL のみの実行で済みますが、特定のエンドポイント用の環境変数が実行シェルに記録されてしまうのは好ましくありません。
# 記録される $ GOOGLE_APPLICATION_CREDENTIALS=&amp;quot;/path/to/google-credentials.json&amp;quot; $ CLIENT_ID=&amp;quot;sample.apps.googleusercontent.com&amp;quot; $ curl &amp;quot;https://iap-protected-app-url&amp;quot;  （変数部分だけコマンドラインから定義してしまえば curl からの実行で済むが、シェルを再起動するまでは変数が実行プロセスに記録されてしまう）
問題はこれだけではありません。 開発環境の動作確認が終わったら本番環境の動作確認です（critical なサービスではない場合、初動の動作確認はカジュアルに curl でヘルスチェックを取ることも多いです）。
今度は本番環境に変わるのでURLや環境変数を書き換える必要があります。 また、開発環境と本番環境のヘルスチェックの行き来をしなきゃいけない場合もあります。 流石にここまでくると面倒くさくて、確認が終わったら削除するであろう取り急ぎなスクリプトにしちゃうことが多いです。
あとからまたヘルスチェックをとりたいと思ったとき これまでは上記の方法でなんとかお茶を濁していたのですが、最近厳しくなってきました。 見ているサービスが多くなってきたためです。
例えばあるサービスの Dev の様子がおかしいとなったとき、開発者が修正をデプロイしたとしても、場合によっては SRE や基盤チームがその後の疎通やサービスの状態をみたりします。 上にあるようなその場しのぎのスクリプトやワンライナーでやっていると、すでにスクリプトを削除していたり履歴を追うのが面倒で、こういうときにヘルスチェック用のパスが何だったのか（/health ? /status ?）、そもそもリクエストすべきサービスの URL がなんだったのか正確に思い出せません。
ツール https://github.com/b4b4r07/req
前に Cloud IAP で保護されたエンドポイントに対して簡単にリクエストを送るために作った CLI ツールの iap_curl が便利だったので、基本的な挙動はそのままに少し手を加えて汎用化しました。</description>
    </item>
    
    <item>
      <title>最強のヒストリ補完を作りました</title>
      <link>https://tellme.tokyo/post/2017/06/13/history/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/06/13/history/</guid>
      <description>最強のヒストリ補完を求めて シェルヒストリに不満を持っていたので自作しました。 今の自分にとっては必要な機能を盛り込んでいて便利に使えていますが、誰かにとっては、もしくは数カ月後の自分にとってはぜんぜん最強じゃないかもしれないです。
以前このようなエントリを書きました。
[http://www.tellme.tokyo/entry/2017/02/14/214231:embed:cite]
このころから (いやもっと前から) シェルのヒストリ補完に不満を持っていました。
 単純にデフォルトの C-r だと目的のものを探しづらい  例えばコマンド名の一部だけだとノイズが多すぎる けどディレクトリは覚えているからそれでもフィルタしたい、とか   他にも色々あって (その理由について先のエントリを見てもらうとして) zsh-history というツールを書きました。
https://github.com/b4b4r07/zsh-history
このときは最強のヒストリ補完ができたと、嬉々として先程のエントリを書いたのです。
しかし、まあ数ヶ月使っていると不便な点が見えてきて、
 複数ホスト間でもヒストリ共有したい ディレクトリだけではなくブランチごとに履歴を持ちたい カジュアルに履歴を消したい などなどの変更を加えるときに SQLite3 だとめんどい パフォーマンスは落ちるかもしれないけどテキストで持ってたほうが何かと便利かも  みたいなことが相まって作り直そうと思ったわけです。
新しく作った 特徴など 前回のネーミングセンスなさから変わらず、単に history となっています (そもそも前回のときのも zsh- prefix をつける必要性なかったので)。
 何ができるかというと、
 peco/fzf などでフィルタできる ブランチとかディレクトリに限定してフィルタできる (任意) 自動でバックアップしてくれる gist 経由で同期できる  GITHUB_TOKEN さえ渡せばよしなにやってくれるので、ユーザは他の PC でトークンを設定して history sync するだけ  同期のタイミングとか時間間隔とか差分量 (100 行以上で同期、など) の設定ができる 履歴を直接編集できる zsh intergrate は書いてるので source misc/zsh/init.</description>
    </item>
    
    <item>
      <title>Crowi 用の API Client 書いて公式に取り込まれた</title>
      <link>https://tellme.tokyo/post/2017/04/04/go-crowi/</link>
      <pubDate>Tue, 04 Apr 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/04/04/go-crowi/</guid>
      <description>Crowi というオープンソースソフトウェアの wiki があります。
 Markdown で書ける wiki で、
 Markdown をオートプレビュー URL (パス構造) でページを作成/表現できる リビジョンヒストリ (差分を管理してくれる) いいね、ブックマーク、ポータル機能、&amp;hellip;  などの特徴があって、とても便利なサービスです。
簡単に Heroku to deploy できるので気になる方は試してみてください。開発者向けにはオールインワンの Docker が有志によってメンテされているので、そちらを試してみても良いかもしれません。
go-crowi Crowi 用の API Client を Go で書きました。
https://github.com/crowi/go-crowi
Go で API Client は初めて書いたのですが、@deeeet さんの記事が参考になりました。
GolangでAPI Clientを実装する | SOTA
もともと、Qiita:Team からの移行ツールを Go で書いていたのですが、Crowi API と通信する部分は外部パッケージとして切り出したほうが汎用的に良いなと、go-crowi を作りました。
https://github.com/b4b4r07/qiita2crowi
このツールは Qiita:Team からのエクスポート用の JSON を食わすと、指定した Crowi に記事を作成してくれるものです。Qiita から画像を取ってきてアッタチメントしたり、コメントなども移行してくれます。
Transfer to Crowi そして今日、Crowi のメインメンテナの @sotarok さんから公式においても良いかも、というお話をいただき transfer しました。</description>
    </item>
    
    <item>
      <title>golang で zsh history を SQL 的に活用する</title>
      <link>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</link>
      <pubDate>Tue, 14 Feb 2017 00:00:00 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2017/02/14/history-golang-sql/</guid>
      <description>僕は開発中、zsh のヒストリー補完の機能をよく使います。具体的には次のような場面が多いです。
 多用するコマンド  結局開発中に使うのはエディタ (vim) と git サブコマンドに集中する ちょちょいと ^N (↑) で履歴をさかのぼる  alias がイケてない場面  「エディタで .zshrc 開いて追加してリロード」が面倒で後回ししがち そして登録せずに終わる の繰り返し&amp;hellip; うろ覚え程度のコマンドの alias 名はもはや思い出せない 結局エディタ開いて見直したり、^R で遡ることに挑戦する  長いコマンド列になるとき  引数が多いとき、多段のパイプで繋いだとき 例えば、複数のパラメータを与えたときの curl コマンド   Ctrl-r (history-incremental-search-backward) よるヒストリーサーチが便利なのはよく知られたことですが、それに加えて peco のようなコマンドラインセレクタと zsh history を組み合わせて、過去に自分が入力したコマンドをその一部の記憶から引き出せるようにしたりして、便利になるようにカスタマイズしていました。
しかし、それでも以下のような不満がありました。
 ディレクトリごとに履歴を持ってほしい  ある特定のディレクトリでのみ使うコマンドなど git checkout ブランチ とか (git 系全般にいえる) プロジェクトのリポジトリとか tmux などで zsh を複数立ち上げているときなどにヒストリーを混同したくない  コマンド履歴にタグを付けたい  コメント (interactive_comments オプション) をつけて保持しておきたい あとあと検索が楽になる  すべての履歴を保持したい  何件まで保存、などは考えたくない 数年前の履歴も引き出せるようにしておきたい ただし数十万〜件になろうともパフォーマンスは落としたくない 標準のヒストリーは数十 MB にもなると、もたつく等の報告例あり  特定の月に使用したコマンド履歴を出したい  一定期間だけ違うプロジェクトにアサインされていたとか  substring search したい  これもディレクトリごとにできるとよし  history が壊れないような仕組みがほしい  突然壊れたとの報告例あり (自分は経験したことないけど) Twitter で検索すると嘆いている人が多い   zsh のオプション (setopt) や Third-party 系のプラグインなどを併用すれば一部の課題は解決できるのですが、同時に満たしてくれるものはなく自作しました。</description>
    </item>
    
    <item>
      <title>特定のワードで Twitter を監視して、検知したら Slack に投げる</title>
      <link>https://tellme.tokyo/post/2016/10/17/twistd/</link>
      <pubDate>Mon, 17 Oct 2016 00:24:32 +0900</pubDate>
      
      <guid>https://tellme.tokyo/post/2016/10/17/twistd/</guid>
      <description>&amp;hellip; というツールを書きました。 Twitter Streaming Daemon なので twistd です。 最近話題の名前衝突ですが、こっちは個人のツールだし一旦気にしないことにします (リポジトリ作ってから気づいた)。
 tl;dr  Twitter Streaming API を利用してツイートを監視する 特定のワードで引っかかったら Slack に通知する 2つをいっぺんに行うコマンドを書いた (デーモンとして利用しましょう)  
※ [&#39;tomato&#39;, &#39;potato&#39;] で引っ掛けてる例
モチベーション zplug (GitHub Organization) ではオーナーの他に数名のコラボレーターの方たちがいます。 開発者同士のコミュニケーションには Slack を用い、GitHub Issues で issue トラッキングをしています。 Slack への GitHub の通知は、Slack のインテグレーション機能 (issue が作られたり P-R が投げられると通知される) を使っています。 これはよくあるスタイルだと思います。
ところが、数ヶ月 Organization を運用して気づいたのが GitHub Issues に上がってこないバグレポートや機能改善、機能要望も結構あるということです。 その多くは Twitter 上でつぶやかれていて、それからは時折 zplug -RT とかで Twitter 検索をしていたのですが、それを他のコラボレーターに共有するのが面倒なことと、定期的なエゴサーチが面倒 (見逃すということもある) で、Twitter を常時監視して zplug についてつぶやかれていたら Slack にポストしてくれるツールはないかと探しておりました。 ちょうど良さそうなツールはないようなので作ることにしました。</description>
    </item>
    
  </channel>
</rss>